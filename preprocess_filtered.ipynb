{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "# import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import random\n",
    "# import re\n",
    "# import shutil\n",
    "\n",
    "# # Set seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "# # Define base directories\n",
    "# base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\"\n",
    "# trainval_dir = os.path.join(base_dir, \"TrainVal\")\n",
    "# color_dir = os.path.join(trainval_dir, \"color\")\n",
    "# label_dir = os.path.join(trainval_dir, \"label\")\n",
    "\n",
    "# # Define destination directories for train and validation splits\n",
    "# train_color_dir = os.path.join(base_dir, \"train\", \"color\")\n",
    "# train_label_dir = os.path.join(base_dir, \"train\", \"label\")\n",
    "# val_color_dir = os.path.join(base_dir, \"val\", \"color\")\n",
    "# val_label_dir = os.path.join(base_dir, \"val\", \"label\")\n",
    "\n",
    "# # Create the destination directories if they don't exist\n",
    "# for d in [train_color_dir, train_label_dir, val_color_dir, val_label_dir]:\n",
    "#     os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# # Find all jpg files in the color folder\n",
    "# image_files = glob.glob(os.path.join(color_dir, \"*.jpg\"))\n",
    "\n",
    "# # Group files by animal name (assumes format like \"Abyssinian_1.jpg\")\n",
    "# groups = {}\n",
    "# pattern = re.compile(r'(.+)_\\d+\\.jpg')  # capture group for the animal name\n",
    "# for image_file in image_files:\n",
    "#     basename = os.path.basename(image_file)\n",
    "#     match = pattern.match(basename)\n",
    "#     if match:\n",
    "#         animal = match.group(1)\n",
    "#     else:\n",
    "#         animal = \"unknown\"\n",
    "#     groups.setdefault(animal, []).append(basename)\n",
    "\n",
    "# # Split the files for each animal into train (80%) and val (20%)\n",
    "# train_list = []\n",
    "# val_list = []\n",
    "# for animal, files in groups.items():\n",
    "#     random.shuffle(files)\n",
    "#     split_index = int(0.8 * len(files))\n",
    "#     train_files = files[:split_index]\n",
    "#     val_files = files[split_index:]\n",
    "#     train_list.extend(train_files)\n",
    "#     val_list.extend(val_files)\n",
    "\n",
    "# # Define output text file paths\n",
    "# train_txt_path = os.path.join(base_dir, \"train.txt\")\n",
    "# val_txt_path = os.path.join(base_dir, \"val.txt\")\n",
    "\n",
    "# # Copy files to new folders and write paths to train.txt and val.txt\n",
    "# with open(train_txt_path, \"w\") as train_file, open(val_txt_path, \"w\") as val_file:\n",
    "#     # Process train split\n",
    "#     for filename in train_list:\n",
    "#         # Copy color image\n",
    "#         src_color = os.path.join(color_dir, filename)\n",
    "#         dst_color = os.path.join(train_color_dir, filename)\n",
    "#         shutil.copy2(src_color, dst_color)\n",
    "        \n",
    "#         # Derive corresponding label filename (change extension from .jpg to .png)\n",
    "#         label_filename = filename.replace(\".jpg\", \".png\")\n",
    "#         src_label = os.path.join(label_dir, label_filename)\n",
    "#         dst_label = os.path.join(train_label_dir, label_filename)\n",
    "#         if os.path.exists(src_label):\n",
    "#             shutil.copy2(src_label, dst_label)\n",
    "        \n",
    "#         # Write relative paths to train.txt (format: \"train/color/<filename> train/label/<label_filename>\")\n",
    "#         train_file.write(f\"{os.path.join('train','color',filename)} {os.path.join('train','label',label_filename)}\\n\")\n",
    "    \n",
    "#     # Process validation split\n",
    "#     for filename in val_list:\n",
    "#         # Copy color image\n",
    "#         src_color = os.path.join(color_dir, filename)\n",
    "#         dst_color = os.path.join(val_color_dir, filename)\n",
    "#         shutil.copy2(src_color, dst_color)\n",
    "        \n",
    "#         # Corresponding label filename\n",
    "#         label_filename = filename.replace(\".jpg\", \".png\")\n",
    "#         src_label = os.path.join(label_dir, label_filename)\n",
    "#         dst_label = os.path.join(val_label_dir, label_filename)\n",
    "#         if os.path.exists(src_label):\n",
    "#             shutil.copy2(src_label, dst_label)\n",
    "        \n",
    "#         # Write relative paths to val.txt\n",
    "#         val_file.write(f\"{os.path.join('val','color',filename)} {os.path.join('val','label',label_filename)}\\n\")\n",
    "\n",
    "# print(\"Data splitting and copying complete.\")\n",
    "# print(f\"Train list written to {train_txt_path}\")\n",
    "# print(f\"Val list written to {val_txt_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get statistics of the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# from collections import Counter\n",
    "\n",
    "# def extract_animal(filepath):\n",
    "#     \"\"\"\n",
    "#     Extracts the animal class from a filename.\n",
    "#     Assumes filename format: AnimalName_123.jpg\n",
    "#     \"\"\"\n",
    "#     # Use regex to extract animal class from the basename.\n",
    "#     pattern = re.compile(r'(.+)_\\d+\\.jpg')\n",
    "#     basename = os.path.basename(filepath)\n",
    "#     match = pattern.match(basename)\n",
    "#     if match:\n",
    "#         return match.group(1)\n",
    "#     else:\n",
    "#         return \"unknown\"\n",
    "\n",
    "# def get_statistics(txt_file):\n",
    "#     \"\"\"\n",
    "#     Reads the text file (each line with two paths separated by whitespace)\n",
    "#     and returns the total count and a Counter with the distribution of animal classes.\n",
    "#     \"\"\"\n",
    "#     counter = Counter()\n",
    "#     total = 0\n",
    "#     with open(txt_file, \"r\") as f:\n",
    "#         for line in f:\n",
    "#             line = line.strip()\n",
    "#             if line:\n",
    "#                 parts = line.split()\n",
    "#                 if len(parts) != 2:\n",
    "#                     print(f\"Warning: Unexpected line format: {line}\")\n",
    "#                     continue\n",
    "#                 # Extract the animal from the color image path (first column)\n",
    "#                 animal = extract_animal(parts[0])\n",
    "#                 counter[animal] += 1\n",
    "#                 total += 1\n",
    "#     return total, counter\n",
    "\n",
    "# def print_statistics(txt_file):\n",
    "#     total, counter = get_statistics(txt_file)\n",
    "#     print(f\"Statistics for {txt_file}:\")\n",
    "#     print(f\"  Total samples: {total}\")\n",
    "#     print(\"  Distribution by animal class:\")\n",
    "#     for animal, count in counter.items():\n",
    "#         print(f\"    {animal}: {count}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Update base_dir if needed\n",
    "#     base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\"\n",
    "#     train_txt_path = os.path.join(base_dir, \"train.txt\")\n",
    "#     val_txt_path = os.path.join(base_dir, \"val.txt\")\n",
    "    \n",
    "#     print_statistics(train_txt_path)\n",
    "#     print()\n",
    "#     print_statistics(val_txt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check image dimension statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import glob\n",
    "# from collections import Counter\n",
    "\n",
    "# # Specify the directory containing your images.\n",
    "# # You can change this to any folder you'd like to analyze.\n",
    "# image_folder = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/TrainVal/color\"\n",
    "\n",
    "# # Find all jpg files in the folder\n",
    "# image_files = glob.glob(os.path.join(image_folder, \"*.jpg\"))\n",
    "\n",
    "# resolutions = []  # List to store (width, height) tuples\n",
    "\n",
    "# for img_path in image_files:\n",
    "#     img = cv2.imread(img_path)\n",
    "#     if img is None:\n",
    "#         print(\"Could not read:\", img_path)\n",
    "#         continue\n",
    "#     height, width = img.shape[:2]\n",
    "#     resolutions.append((width, height))\n",
    "\n",
    "# # If any images were found, calculate statistics.\n",
    "# if resolutions:\n",
    "#     widths = [w for w, h in resolutions]\n",
    "#     heights = [h for w, h in resolutions]\n",
    "#     avg_width = sum(widths) / len(widths)\n",
    "#     avg_height = sum(heights) / len(heights)\n",
    "#     min_width = min(widths)\n",
    "#     max_width = max(widths)\n",
    "#     min_height = min(heights)\n",
    "#     max_height = max(heights)\n",
    "    \n",
    "#     # Count unique resolution occurrences\n",
    "#     resolution_counter = Counter(resolutions)\n",
    "    \n",
    "#     print(\"Total images:\", len(resolutions))\n",
    "#     print(f\"Average resolution: {int(avg_width)} x {int(avg_height)}\")\n",
    "#     print(f\"Minimum width: {min_width}, Minimum height: {min_height}\")\n",
    "#     print(f\"Maximum width: {max_width}, Maximum height: {max_height}\")\n",
    "#     print(\"\\nUnique resolutions (width x height) and counts:\")\n",
    "#     for res, count in resolution_counter.items():\n",
    "#         print(f\"{res[0]} x {res[1]}: {count}\")\n",
    "# else:\n",
    "#     print(\"No images found in the specified folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Path to an example image\n",
    "# image_path = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/TrainVal/color/yorkshire_terrier_144.jpg\"\n",
    "\n",
    "# # Load the original image (OpenCV loads in BGR format)\n",
    "# original = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "# if original is None:\n",
    "#     raise ValueError(\"Could not load the image. Please check the image path.\")\n",
    "\n",
    "# # Convert the image from BGR to RGB for display purposes\n",
    "# original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# # Define the target size (for example, 256x256)\n",
    "# TARGET_WIDTH, TARGET_HEIGHT = 256, 256\n",
    "# target_size = (TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "# # Resize the image using bilinear interpolation\n",
    "# resized = cv2.resize(original_rgb, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "# # Display the original and resized images side by side\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.imshow(original_rgb)\n",
    "# plt.title(\"Original Image\")\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.imshow(resized)\n",
    "# plt.title(\"Resized (Interpolated) Image\")\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize一个dictionary，对每个image resize之前，记录它的height和width并写入字典，最后将字典写入一个叫original_sizes.json的file里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Original sizes saved to /Users/bin/Desktop/CV_Assignment/Dataset_filtered/original_sizes.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Set target dimensions (adjust as needed)\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "target_size = (TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "# Base directory (adjust this to your setup)\n",
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\"\n",
    "\n",
    "# Directories for train and val splits\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "\n",
    "# Create destination directories:\n",
    "# For training, we resize images but copy masks unchanged.\n",
    "resized_train_color_dir = os.path.join(base_dir, \"train_resized\", \"color\")\n",
    "resized_train_label_dir = os.path.join(base_dir, \"train_resized\", \"label\")\n",
    "\n",
    "# For validation, we resize images and copy masks unchanged.\n",
    "resized_val_color_dir = os.path.join(base_dir, \"val_resized\", \"color\")\n",
    "resized_val_label_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "\n",
    "for d in [resized_train_color_dir, resized_train_label_dir,\n",
    "          resized_val_color_dir, resized_val_label_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Dictionary to store original image sizes before resizing\n",
    "original_sizes = {}\n",
    "\n",
    "def resize_and_save(src_path, dst_path, target_size, original_sizes_dict):\n",
    "    \"\"\"\n",
    "    Resize an image, save it, and record its original size.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error reading:\", src_path)\n",
    "        return\n",
    "    \n",
    "    # Store original size before resizing\n",
    "    img_name = os.path.basename(src_path).replace(\".jpg\", \"\")  # Remove file extension\n",
    "    original_sizes_dict[img_name] = img.shape[:2]  # Store (height, width)\n",
    "\n",
    "    # Resize and save\n",
    "    resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(dst_path, resized)\n",
    "\n",
    "def process_data(color_source, label_source, resized_color_dest, resized_label_dest, original_sizes_dict):\n",
    "    \"\"\"\n",
    "    Processes a dataset split:\n",
    "    - Resizes color images and stores original sizes.\n",
    "    - Copies label masks unchanged.\n",
    "    \"\"\"\n",
    "    # Resize color images\n",
    "    for filename in sorted(os.listdir(color_source)):\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            src_path = os.path.join(color_source, filename)\n",
    "            dst_path = os.path.join(resized_color_dest, filename)\n",
    "            resize_and_save(src_path, dst_path, target_size, original_sizes_dict)\n",
    "\n",
    "    # Copy masks unchanged\n",
    "    for filename in sorted(os.listdir(label_source)):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            src_path = os.path.join(label_source, filename)\n",
    "            dst_path = os.path.join(resized_label_dest, filename)\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Process Training Data\n",
    "# -----------------------------------------\n",
    "train_color_source = os.path.join(train_dir, \"color\")\n",
    "train_label_source = os.path.join(train_dir, \"label\")\n",
    "\n",
    "process_data(train_color_source, train_label_source, resized_train_color_dir, resized_train_label_dir, original_sizes)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Process Validation Data\n",
    "# -----------------------------------------\n",
    "val_color_source = os.path.join(val_dir, \"color\")\n",
    "val_label_source = os.path.join(val_dir, \"label\")\n",
    "\n",
    "process_data(val_color_source, val_label_source, resized_val_color_dir, resized_val_label_dir, original_sizes)\n",
    "\n",
    "# Save original sizes to a JSON file\n",
    "original_size_json_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "with open(original_size_json_path, \"w\") as f:\n",
    "    json.dump(original_sizes, f, indent=4)\n",
    "\n",
    "print(f\"Processing complete. Original sizes saved to {original_size_json_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randaugment (Do the augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from PIL import Image, ImageOps, ImageEnhance\n",
    "# import math\n",
    "# from torchvision.transforms import functional as F\n",
    "# from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# # Define the RandAugment operation pool (14 ops as in the original paper)\n",
    "# RA_OPERATIONS = [\n",
    "#     \"Identity\", \"AutoContrast\", \"Equalize\",\n",
    "#     \"Rotate\", \"Solarize\", \"Color\", \"Posterize\",\n",
    "#     \"Contrast\", \"Brightness\", \"Sharpness\",\n",
    "#     \"ShearX\", \"ShearY\", \"TranslateX\", \"TranslateY\"\n",
    "# ]\n",
    "\n",
    "# def apply_operation(img, mask, op_name, magnitude):\n",
    "#     \"\"\"\n",
    "#     Apply a single augmentation operation to the image (and mask, if applicable).\n",
    "#     'magnitude' is on a 0-10 scale indicating severity.\n",
    "#     \"\"\"\n",
    "#     if op_name == \"Identity\":\n",
    "#         return img, mask  # no change\n",
    "\n",
    "#     if op_name == \"AutoContrast\":\n",
    "#         img = ImageOps.autocontrast(img)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Equalize\":\n",
    "#         img = ImageOps.equalize(img)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Rotate\":\n",
    "#         max_deg = 30.0\n",
    "#         angle = magnitude / 10.0 * max_deg\n",
    "#         if random.random() < 0.5:\n",
    "#             angle = -angle\n",
    "#         img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "#         mask = mask.rotate(angle, resample=Image.NEAREST, fillcolor=0)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Solarize\":\n",
    "#         thresh = int(256 - (magnitude / 10.0) * 256)\n",
    "#         img = ImageOps.solarize(img, thresh)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Color\":\n",
    "#         factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "#         if random.random() < 0.5:\n",
    "#             factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "#         img = ImageEnhance.Color(img).enhance(factor)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Posterize\":\n",
    "#         bits = int(round(8 - (magnitude / 10.0) * 4))\n",
    "#         bits = max(1, bits)\n",
    "#         img = ImageOps.posterize(img, bits)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Contrast\":\n",
    "#         factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "#         if random.random() < 0.5:\n",
    "#             factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "#         img = ImageEnhance.Contrast(img).enhance(factor)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Brightness\":\n",
    "#         factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "#         if random.random() < 0.5:\n",
    "#             factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "#         img = ImageEnhance.Brightness(img).enhance(factor)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"Sharpness\":\n",
    "#         factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "#         if random.random() < 0.5:\n",
    "#             factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "#         img = ImageEnhance.Sharpness(img).enhance(factor)\n",
    "#         return img, mask\n",
    "\n",
    "#     # Geometric operations: these need to be applied identically to the mask\n",
    "#     if op_name == \"ShearX\":\n",
    "#         shear_factor = magnitude / 10.0 * 0.3\n",
    "#         if random.random() < 0.5:\n",
    "#             shear_factor = -shear_factor\n",
    "#         shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "#         img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "#                        shear=(shear_degrees, 0.0),\n",
    "#                        interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "#         mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "#                         shear=(shear_degrees, 0.0),\n",
    "#                         interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"ShearY\":\n",
    "#         shear_factor = magnitude / 10.0 * 0.3\n",
    "#         if random.random() < 0.5:\n",
    "#             shear_factor = -shear_factor\n",
    "#         shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "#         img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "#                        shear=(0.0, shear_degrees),\n",
    "#                        interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "#         mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "#                         shear=(0.0, shear_degrees),\n",
    "#                         interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"TranslateX\":\n",
    "#         max_frac = 0.45\n",
    "#         dx = int(round(magnitude / 10.0 * max_frac * img.width))\n",
    "#         if random.random() < 0.5:\n",
    "#             dx = -dx\n",
    "#         img = F.affine(img, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "#                        shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "#         mask = F.affine(mask, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "#                         shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "#         return img, mask\n",
    "\n",
    "#     if op_name == \"TranslateY\":\n",
    "#         max_frac = 0.45\n",
    "#         dy = int(round(magnitude / 10.0 * max_frac * img.height))\n",
    "#         if random.random() < 0.5:\n",
    "#             dy = -dy\n",
    "#         img = F.affine(img, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "#                        shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "#         mask = F.affine(mask, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "#                         shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "#         return img, mask\n",
    "\n",
    "#     return img, mask\n",
    "\n",
    "# def randaugment_image_mask(img, mask, N, M):\n",
    "#     \"\"\"Apply RandAugment (N operations with magnitude M) to the given PIL image and mask.\"\"\"\n",
    "#     ops = random.sample(RA_OPERATIONS, N)  # choose N distinct ops at random\n",
    "#     for op in ops:\n",
    "#         img, mask = apply_operation(img, mask, op, M)\n",
    "#     return img, mask\n",
    "\n",
    "# def run_randaugment_train_resized(input_base, output_base, N=2, M=9, num_aug=3):\n",
    "#     \"\"\"\n",
    "#     Process each image-mask pair from the resized training data.\n",
    "    \n",
    "#     Expects:\n",
    "#       - Images in:  input_base/train_resized/color\n",
    "#       - Masks in:   input_base/train_resized/label\n",
    "    \n",
    "#     Saves augmented outputs in:\n",
    "#       - output_base/train_randaugmented/color\n",
    "#       - output_base/train_randaugmented/label\n",
    "    \n",
    "#     Additionally, copies the original image and mask.\n",
    "#     Generates 'num_aug' augmented images per original image.\n",
    "#     \"\"\"\n",
    "#     in_img_dir = os.path.join(input_base, \"train_resized\", \"color\")\n",
    "#     in_mask_dir = os.path.join(input_base, \"train_resized\", \"label\")\n",
    "#     out_img_dir = os.path.join(output_base, \"train_randaugmented\", \"color\")\n",
    "#     out_mask_dir = os.path.join(output_base, \"train_randaugmented\", \"label\")\n",
    "#     os.makedirs(out_img_dir, exist_ok=True)\n",
    "#     os.makedirs(out_mask_dir, exist_ok=True)\n",
    "\n",
    "#     for filename in os.listdir(in_img_dir):\n",
    "#         if not filename.lower().endswith(\".jpg\"):\n",
    "#             continue\n",
    "#         img_path = os.path.join(in_img_dir, filename)\n",
    "#         base_name, ext = os.path.splitext(filename)\n",
    "#         # Try common mask extensions (often masks are stored as .png)\n",
    "#         mask_candidates = [base_name + \".png\", base_name + \".jpg\", base_name + \".jpeg\", base_name + \".bmp\", base_name + \".tif\"]\n",
    "#         mask_path = None\n",
    "#         for cand in mask_candidates:\n",
    "#             cand_path = os.path.join(in_mask_dir, cand)\n",
    "#             if os.path.exists(cand_path):\n",
    "#                 mask_path = cand_path\n",
    "#                 break\n",
    "#         if mask_path is None:\n",
    "#             print(f\"Mask for image {filename} not found, skipping.\")\n",
    "#             continue\n",
    "\n",
    "#         img = Image.open(img_path).convert(\"RGB\")\n",
    "#         mask = Image.open(mask_path)\n",
    "#         if mask.mode not in [\"L\", \"I\"]:\n",
    "#             mask = mask.convert(\"L\")\n",
    "\n",
    "#         # Save the original image and mask in the output folders\n",
    "#         orig_img_path = os.path.join(out_img_dir, f\"{base_name}_orig.jpg\")\n",
    "#         orig_mask_path = os.path.join(out_mask_dir, f\"{base_name}_orig.png\")\n",
    "#         img.save(orig_img_path)\n",
    "#         mask.save(orig_mask_path)\n",
    "#         print(f\"Saved original image to {orig_img_path} and mask to {orig_mask_path}\")\n",
    "\n",
    "#         # Generate and save augmented versions\n",
    "#         for i in range(num_aug):\n",
    "#             aug_img, aug_mask = randaugment_image_mask(img, mask, N, M)\n",
    "#             out_img_path = os.path.join(out_img_dir, f\"{base_name}_aug_{i}.jpg\")\n",
    "#             out_mask_path = os.path.join(out_mask_dir, f\"{base_name}_aug_{i}.png\")\n",
    "#             aug_img.save(out_img_path)\n",
    "#             aug_mask.save(out_mask_path)\n",
    "#             print(f\"Saved augmented image to {out_img_path} and mask to {out_mask_path}\")\n",
    "\n",
    "# # --- Example usage in a notebook cell ---\n",
    "# # Set your base directory. In your case, it is:\n",
    "# base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\"\n",
    "# # We'll use the same base directory for output (augmented data will be saved under a new subfolder)\n",
    "# run_randaugment_train_resized(base_dir, base_dir, N=2, M=9, num_aug=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将images和masks都写入DataLoader里，但同时也要记录每张image的name以便后面查询mask的original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Image Filenames: ['Abyssinian_10', 'japanese_chin_172', 'boxer_139', 'samoyed_162', 'basset_hound_142', 'havanese_105', 'miniature_pinscher_120', 'saint_bernard_115', 'Birman_102', 'scottish_terrier_152', 'havanese_103', 'chihuahua_137', 'samoyed_14', 'Maine_Coon_176', 'Bombay_12', 'basset_hound_157', 'basset_hound_108', 'Sphynx_196', 'leonberger_123', 'english_cocker_spaniel_158', 'Russian_Blue_162', 'miniature_pinscher_122', 'newfoundland_128', 'Siamese_147', 'english_cocker_spaniel_117', 'Russian_Blue_116', 'basset_hound_112', 'pomeranian_148', 'great_pyrenees_188', 'saint_bernard_155', 'saint_bernard_182', 'saint_bernard_157']\n",
      "Batch Mask Filenames: ['Abyssinian_10', 'japanese_chin_172', 'boxer_139', 'samoyed_162', 'basset_hound_142', 'havanese_105', 'miniature_pinscher_120', 'saint_bernard_115', 'Birman_102', 'scottish_terrier_152', 'havanese_103', 'chihuahua_137', 'samoyed_14', 'Maine_Coon_176', 'Bombay_12', 'basset_hound_157', 'basset_hound_108', 'Sphynx_196', 'leonberger_123', 'english_cocker_spaniel_158', 'Russian_Blue_162', 'miniature_pinscher_122', 'newfoundland_128', 'Siamese_147', 'english_cocker_spaniel_117', 'Russian_Blue_116', 'basset_hound_112', 'pomeranian_148', 'great_pyrenees_188', 'saint_bernard_155', 'saint_bernard_182', 'saint_bernard_157']\n"
     ]
    }
   ],
   "source": [
    "from custom_dataset import CustomDataset\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize only for training input\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = CustomDataset(\n",
    "    image_dir=\"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/train_randaugmented/color\",\n",
    "    mask_dir=\"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/train_randaugmented/label\",\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Custom collate function to handle filenames\n",
    "def custom_collate_fn(batch):\n",
    "    images, masks, img_names, mask_names = zip(*batch)\n",
    "\n",
    "    img_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in img_names]\n",
    "    mask_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in mask_names]\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    masks = torch.stack(masks)\n",
    "    return images, masks, list(img_names), list(mask_names)\n",
    "\n",
    "# Create DataLoader with shuffle=True but keeping filenames\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, \n",
    "                              pin_memory=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Test DataLoader\n",
    "for images, masks, img_names, mask_names in train_dataloader:\n",
    "    print(\"Batch Image Filenames:\", img_names)\n",
    "    print(\"Batch Mask Filenames:\", mask_names)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "import torch.optim as optim\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=1)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# summary(model=model, \n",
    "#         input_size=(32, 3, 256, 256), # make sure this is \"input_size\", not \"input_shape\"\n",
    "#         # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# ) \n",
    "\n",
    "x = torch.randn(32, 3, 256, 256)  # Example input tensor\n",
    "output = model(x)\n",
    "print(output.shape)  # Expected: torch.Size([1, 1, 256, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_logits_before_argmax(logits, original_sizes):\n",
    "    \"\"\"\n",
    "    Resize logits to their original image sizes before applying argmax.\n",
    "    \n",
    "    Args:\n",
    "        logits (torch.Tensor): Predicted logits of shape (batch_size, 1, 256, 256).\n",
    "        original_sizes (list of tuples): List of (H, W) for each image in the batch.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of resized masks [(1, H1, W1), (1, H2, W2), ...], each with its corresponding original size.\n",
    "    \"\"\"\n",
    "    resized_masks = []\n",
    "    for i in range(len(logits)):  \n",
    "        orig_h, orig_w = original_sizes[i]  # Get the original height and width for each mask\n",
    "        resized_logit = F.interpolate(logits[i].unsqueeze(0),  # (1, 256, 256) → (1, H, W)\n",
    "                                      size=(orig_h, orig_w), \n",
    "                                      mode=\"bilinear\", \n",
    "                                      align_corners=False)  # Bilinear interpolation ensures smooth resizing\n",
    "\n",
    "        # **Apply thresholding to convert logits into binary masks (0/1)**\n",
    "        binary_mask = (resized_logit > 0.5).float()  # Thresholding to obtain binary mask\n",
    "        resized_masks.append(binary_mask)  # Store the resized binary mask in a list\n",
    "\n",
    "    return resized_masks  # Return a list containing masks of different sizes\n",
    "\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()  # (can be changed to Dice Loss if needed)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop iterating over the DataLoader\n",
    "for images, masks, original_sizes in train_dataloader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 1️⃣ Forward pass: Get predicted logits from the UNet model (batch_size, 1, 256, 256)\n",
    "    logits = model(images)\n",
    "\n",
    "    # 2️⃣ Resize the logits to match their original sizes before applying argmax\n",
    "    resized_masks = resize_logits_before_argmax(logits, original_sizes)  \n",
    "\n",
    "    # 3️⃣ Compute the loss for each mask individually\n",
    "    total_loss = 0\n",
    "    for pred_mask, gt_mask in zip(resized_masks, masks):\n",
    "        loss = loss_fn(pred_mask, gt_mask)  # Compute loss for each individual sample\n",
    "        total_loss += loss  # Accumulate loss for the batch\n",
    "    \n",
    "    # 4️⃣ Compute the average loss over the batch\n",
    "    total_loss /= len(resized_masks)  \n",
    "\n",
    "    # 5️⃣ Backpropagation and optimizer update\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Loss: {total_loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
