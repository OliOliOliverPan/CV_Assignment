{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "# import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(\"data/Dataset_filtered\")\n",
    "\n",
    "trainval_image_path = image_path / \"TrainVal/color\"\n",
    "test_image_path = image_path / \"Test/color\"\n",
    "\n",
    "trainval_jpg_count = sum(1 for file in os.listdir(trainval_image_path) if file.lower().endswith(\".jpg\"))\n",
    "print(f\"Number of training and validation images: {trainval_jpg_count}\") #3673\n",
    "\n",
    "test_jpg_count = sum(1 for file in os.listdir(test_image_path) if file.lower().endswith(\".jpg\"))\n",
    "print(f\"Number of test images: {test_jpg_count}\") #3694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training and Validation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# def train_val_split(split_ratio=0.2):\n",
    "#     \"\"\"\n",
    "#     Splits the dataset into training and validation sets with a species-specific split.\n",
    "#     For each species (class), split_ratio of the samples will be assigned to validation.\n",
    "#     Updates 'train.txt' and 'val.txt' in the 'annotations' directory.\n",
    "\n",
    "#     Assumes each line in trainval.txt is formatted as:\n",
    "#         image_name species [other_info...]\n",
    "    \n",
    "#     Parameters:\n",
    "#         split_ratio (float): The fraction of images per species to be used for validation (default: 0.2)\n",
    "#     \"\"\"\n",
    "#     annotations_dir = Path(\"Data/annotations\")\n",
    "#     trainval_txt = annotations_dir / \"trainval.txt\"\n",
    "#     train_txt = annotations_dir / \"train.txt\"\n",
    "#     val_txt = annotations_dir / \"val.txt\"\n",
    "\n",
    "#     # Read the trainval.txt file\n",
    "#     if not trainval_txt.exists():\n",
    "#         raise FileNotFoundError(f\"trainval.txt not found in {annotations_dir}\")\n",
    "\n",
    "#     with open(trainval_txt, \"r\") as f:\n",
    "#         lines = f.readlines()\n",
    "\n",
    "#     # Group lines by species (assuming species is the second token in each line)\n",
    "#     species_dict = {}\n",
    "#     for line in lines:\n",
    "#         tokens = line.strip().split()\n",
    "#         if len(tokens) < 2:\n",
    "#             continue  # Skip lines that don't have enough tokens\n",
    "#         species = tokens[1]\n",
    "#         species_dict.setdefault(species, []).append(line)\n",
    "\n",
    "#     train_lines = []\n",
    "#     val_lines = []\n",
    "#     # For each species, select a fraction of samples for validation\n",
    "#     for species, species_lines in species_dict.items():\n",
    "#         n_samples = len(species_lines)\n",
    "#         n_val = int(n_samples * split_ratio)\n",
    "#         # If rounding leads to 0 but there is at least one sample, ensure at least one goes to val\n",
    "#         if n_val == 0 and n_samples > 0:\n",
    "#             n_val = 1\n",
    "#         indices = np.arange(n_samples)\n",
    "#         val_indices = np.random.choice(indices, size=n_val, replace=False)\n",
    "#         for idx, line in enumerate(species_lines):\n",
    "#             if idx in val_indices:\n",
    "#                 val_lines.append(line)\n",
    "#             else:\n",
    "#                 train_lines.append(line)\n",
    "\n",
    "#     # Write new train.txt and val.txt files\n",
    "#     with open(train_txt, \"w\") as f_train:\n",
    "#         f_train.writelines(train_lines)\n",
    "#     with open(val_txt, \"w\") as f_val:\n",
    "#         f_val.writelines(val_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# np.random.seed(42)\n",
    "# train_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def copy_images_to_train_val():\n",
    "#     \"\"\"\n",
    "#     Copies images and labels for training and validation sets based on the annotation files.\n",
    "    \n",
    "#     For each line in train.txt and val.txt, the first token (image name) is used to locate:\n",
    "#         - the image file: Dataset_filtered/TrainVal/color/<image_name>.jpg\n",
    "#         - the mask file: Dataset_filtered/TrainVal/label/<image_name>.png\n",
    "\n",
    "#     The files are then copied to:\n",
    "#         - Training set: Dataset_filtered/Train/color and Dataset_filtered/Train/label\n",
    "#         - Validation set: Dataset_filtered/Val/color and Dataset_filtered/Val/label\n",
    "#     \"\"\"\n",
    "#     # Define source directories\n",
    "#     base_dir = Path(\"Data/Dataset_filtered\")\n",
    "#     source_dir = base_dir / \"TrainVal\"\n",
    "#     source_color = source_dir / \"color\"\n",
    "#     source_label = source_dir / \"label\"\n",
    "    \n",
    "#     # Define destination directories for training and validation\n",
    "#     train_dir = base_dir / \"Train\"\n",
    "#     val_dir = base_dir / \"Val\"\n",
    "#     train_color = train_dir / \"color\"\n",
    "#     train_label = train_dir / \"label\"\n",
    "#     val_color = val_dir / \"color\"\n",
    "#     val_label = val_dir / \"label\"\n",
    "    \n",
    "#     # Create destination directories if they do not exist\n",
    "#     for folder in [train_color, train_label, val_color, val_label]:\n",
    "#         folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # Define the annotations directory and files\n",
    "#     annotations_dir = Path(\"Data/annotations\")\n",
    "#     train_txt = annotations_dir / \"train.txt\"\n",
    "#     val_txt = annotations_dir / \"val.txt\"\n",
    "    \n",
    "#     def copy_files(annotation_file, dest_color, dest_label):\n",
    "#         if not annotation_file.exists():\n",
    "#             raise FileNotFoundError(f\"{annotation_file} not found.\")\n",
    "#         with open(annotation_file, \"r\") as f:\n",
    "#             lines = f.readlines()\n",
    "#         for line in lines:\n",
    "#             tokens = line.strip().split()\n",
    "#             if not tokens:\n",
    "#                 continue  # Skip empty lines\n",
    "#             image_name = tokens[0]\n",
    "#             # Define source file paths\n",
    "#             src_image = source_color / f\"{image_name}.jpg\"\n",
    "#             src_label = source_label / f\"{image_name}.png\"\n",
    "#             # Copy image file if it exists\n",
    "#             if src_image.exists():\n",
    "#                 shutil.copy(str(src_image), str(dest_color / src_image.name))\n",
    "#             else:\n",
    "#                 print(f\"Warning: {src_image} not found.\")\n",
    "#             # Copy label file if it exists\n",
    "#             if src_label.exists():\n",
    "#                 shutil.copy(str(src_label), str(dest_label / src_label.name))\n",
    "#             else:\n",
    "#                 print(f\"Warning: {src_label} not found.\")\n",
    "    \n",
    "#     # Copy files for the training set\n",
    "#     copy_files(train_txt, train_color, train_label)\n",
    "#     # Copy files for the validation set\n",
    "#     copy_files(val_txt, val_color, val_label)\n",
    "    \n",
    "#     # print(\"Image and label copying completed.\")\n",
    "\n",
    "# copy_images_to_train_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Images to Make Them Consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x103b11a50>\n"
     ]
    }
   ],
   "source": [
    "from segmentation_dataset import SegmentationDataset\n",
    "    \n",
    "class AugmentedTransform:\n",
    "    def __init__(self, size=(256, 256)):\n",
    "        self.size = size\n",
    "\n",
    "        # Image augmentations (applied to images)\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize(self.size),\n",
    "            transforms.ToTensor()\n",
    "            # transforms.RandomHorizontalFlip(p=0.5),  # 50% chance to flip\n",
    "            # transforms.RandomRotation(degrees=15),  # Rotate within ±15 degrees\n",
    "            # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),  # Affine transform\n",
    "            # transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Adjust colors\n",
    "            # transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize (adjust values if needed)\n",
    "        ])\n",
    "\n",
    "        # Mask transformations (aligned with image transformations)\n",
    "        self.mask_transform = transforms.Compose([\n",
    "            transforms.Resize(self.size, interpolation=transforms.InterpolationMode.NEAREST),  # Resize mask\n",
    "            transforms.PILToTensor(),  # Convert to tensor (mask remains an integer class map)\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        \"\"\"\n",
    "        Applies the same augmentations to both image and mask while ensuring mask remains a label map.\n",
    "        \"\"\"\n",
    "        # Random horizontal flip\n",
    "        # if random.random() > 0.5:\n",
    "        #     image = F.hflip(image)\n",
    "        #     mask = F.hflip(mask)\n",
    "\n",
    "        # Random rotation (ensuring mask rotates the same way)\n",
    "        # angle = random.uniform(-15, 15)  # Rotate between -15 and 15 degrees\n",
    "        # image = F.rotate(image, angle)\n",
    "        # mask = F.rotate(mask, angle)\n",
    "\n",
    "        # Apply other transformations\n",
    "        image = self.image_transform(image)\n",
    "        mask = self.mask_transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "    \n",
    "# Instantiate dataset\n",
    "train_data = SegmentationDataset(\n",
    "    image_dir=\"Data/Dataset_filtered/Train/color\",\n",
    "    mask_dir=\"Data/Dataset_filtered/Train/label\",\n",
    "    transform=AugmentedTransform(size=(256, 256))\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)\n",
    "print(train_dataloader)\n",
    "\n",
    "\n",
    "# for images, masks in train_dataloader:\n",
    "#     print(\"Batch of images shape:\", images.shape)\n",
    "#     print(\"Batch of masks shape:\", masks.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "UNet (UNet)                              [32, 3, 256, 256]    [32, 1, 128, 128]    --                   True\n",
       "├─Sequential (initial)                   [32, 3, 256, 256]    [32, 64, 128, 128]   --                   True\n",
       "│    └─Conv2d (0)                        [32, 3, 256, 256]    [32, 64, 128, 128]   9,408                True\n",
       "│    └─BatchNorm2d (1)                   [32, 64, 128, 128]   [32, 64, 128, 128]   128                  True\n",
       "│    └─ReLU (2)                          [32, 64, 128, 128]   [32, 64, 128, 128]   --                   --\n",
       "├─MaxPool2d (maxpool)                    [32, 64, 128, 128]   [32, 64, 64, 64]     --                   --\n",
       "├─Sequential (layer1)                    [32, 64, 64, 64]     [32, 64, 64, 64]     --                   True\n",
       "│    └─BasicBlock (0)                    [32, 64, 64, 64]     [32, 64, 64, 64]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 64, 64]     [32, 64, 64, 64]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 64, 64]     [32, 64, 64, 64]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    └─BasicBlock (1)                    [32, 64, 64, 64]     [32, 64, 64, 64]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 64, 64]     [32, 64, 64, 64]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 64, 64]     [32, 64, 64, 64]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    └─BasicBlock (2)                    [32, 64, 64, 64]     [32, 64, 64, 64]     --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 64, 64]     [32, 64, 64, 64]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 64, 64, 64]     [32, 64, 64, 64]     36,864               True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 64, 64, 64]     [32, 64, 64, 64]     128                  True\n",
       "│    │    └─ReLU (relu)                  [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "├─Sequential (layer2)                    [32, 64, 64, 64]     [32, 128, 32, 32]    --                   True\n",
       "│    └─BasicBlock (0)                    [32, 64, 64, 64]     [32, 128, 32, 32]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 64, 64, 64]     [32, 128, 32, 32]    73,728               True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─Sequential (downsample)      [32, 64, 64, 64]     [32, 128, 32, 32]    8,448                True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    └─BasicBlock (1)                    [32, 128, 32, 32]    [32, 128, 32, 32]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    └─BasicBlock (2)                    [32, 128, 32, 32]    [32, 128, 32, 32]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    └─BasicBlock (3)                    [32, 128, 32, 32]    [32, 128, 32, 32]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 128, 32, 32]    [32, 128, 32, 32]    147,456              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 128, 32, 32]    [32, 128, 32, 32]    256                  True\n",
       "│    │    └─ReLU (relu)                  [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "├─Sequential (layer3)                    [32, 128, 32, 32]    [32, 256, 16, 16]    --                   True\n",
       "│    └─BasicBlock (0)                    [32, 128, 32, 32]    [32, 256, 16, 16]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 128, 32, 32]    [32, 256, 16, 16]    294,912              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─Sequential (downsample)      [32, 128, 32, 32]    [32, 256, 16, 16]    33,280               True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    └─BasicBlock (1)                    [32, 256, 16, 16]    [32, 256, 16, 16]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    └─BasicBlock (2)                    [32, 256, 16, 16]    [32, 256, 16, 16]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    └─BasicBlock (3)                    [32, 256, 16, 16]    [32, 256, 16, 16]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    └─BasicBlock (4)                    [32, 256, 16, 16]    [32, 256, 16, 16]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    └─BasicBlock (5)                    [32, 256, 16, 16]    [32, 256, 16, 16]    --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 256, 16, 16]    [32, 256, 16, 16]    589,824              True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 256, 16, 16]    [32, 256, 16, 16]    512                  True\n",
       "│    │    └─ReLU (relu)                  [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "├─Sequential (layer4)                    [32, 256, 16, 16]    [32, 512, 8, 8]      --                   True\n",
       "│    └─BasicBlock (0)                    [32, 256, 16, 16]    [32, 512, 8, 8]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 256, 16, 16]    [32, 512, 8, 8]      1,179,648            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 8, 8]      [32, 512, 8, 8]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 8, 8]      [32, 512, 8, 8]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 8, 8]      [32, 512, 8, 8]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 8, 8]      [32, 512, 8, 8]      1,024                True\n",
       "│    │    └─Sequential (downsample)      [32, 256, 16, 16]    [32, 512, 8, 8]      132,096              True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 8, 8]      [32, 512, 8, 8]      --                   --\n",
       "│    └─BasicBlock (1)                    [32, 512, 8, 8]      [32, 512, 8, 8]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 8, 8]      [32, 512, 8, 8]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 8, 8]      [32, 512, 8, 8]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 8, 8]      [32, 512, 8, 8]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 8, 8]      [32, 512, 8, 8]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 8, 8]      [32, 512, 8, 8]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 8, 8]      [32, 512, 8, 8]      --                   --\n",
       "│    └─BasicBlock (2)                    [32, 512, 8, 8]      [32, 512, 8, 8]      --                   True\n",
       "│    │    └─Conv2d (conv1)               [32, 512, 8, 8]      [32, 512, 8, 8]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn1)            [32, 512, 8, 8]      [32, 512, 8, 8]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 8, 8]      [32, 512, 8, 8]      --                   --\n",
       "│    │    └─Conv2d (conv2)               [32, 512, 8, 8]      [32, 512, 8, 8]      2,359,296            True\n",
       "│    │    └─BatchNorm2d (bn2)            [32, 512, 8, 8]      [32, 512, 8, 8]      1,024                True\n",
       "│    │    └─ReLU (relu)                  [32, 512, 8, 8]      [32, 512, 8, 8]      --                   --\n",
       "├─ConvTranspose2d (up4)                  [32, 512, 8, 8]      [32, 256, 16, 16]    524,544              True\n",
       "├─Sequential (dec4)                      [32, 512, 16, 16]    [32, 256, 16, 16]    --                   True\n",
       "│    └─Conv2d (0)                        [32, 512, 16, 16]    [32, 256, 16, 16]    1,179,904            True\n",
       "│    └─ReLU (1)                          [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "│    └─Conv2d (2)                        [32, 256, 16, 16]    [32, 256, 16, 16]    590,080              True\n",
       "│    └─ReLU (3)                          [32, 256, 16, 16]    [32, 256, 16, 16]    --                   --\n",
       "├─ConvTranspose2d (up3)                  [32, 256, 16, 16]    [32, 128, 32, 32]    131,200              True\n",
       "├─Sequential (dec3)                      [32, 256, 32, 32]    [32, 128, 32, 32]    --                   True\n",
       "│    └─Conv2d (0)                        [32, 256, 32, 32]    [32, 128, 32, 32]    295,040              True\n",
       "│    └─ReLU (1)                          [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "│    └─Conv2d (2)                        [32, 128, 32, 32]    [32, 128, 32, 32]    147,584              True\n",
       "│    └─ReLU (3)                          [32, 128, 32, 32]    [32, 128, 32, 32]    --                   --\n",
       "├─ConvTranspose2d (up2)                  [32, 128, 32, 32]    [32, 64, 64, 64]     32,832               True\n",
       "├─Sequential (dec2)                      [32, 128, 64, 64]    [32, 64, 64, 64]     --                   True\n",
       "│    └─Conv2d (0)                        [32, 128, 64, 64]    [32, 64, 64, 64]     73,792               True\n",
       "│    └─ReLU (1)                          [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "│    └─Conv2d (2)                        [32, 64, 64, 64]     [32, 64, 64, 64]     36,928               True\n",
       "│    └─ReLU (3)                          [32, 64, 64, 64]     [32, 64, 64, 64]     --                   --\n",
       "├─ConvTranspose2d (up1)                  [32, 64, 64, 64]     [32, 64, 128, 128]   16,448               True\n",
       "├─Sequential (dec1)                      [32, 128, 128, 128]  [32, 64, 128, 128]   --                   True\n",
       "│    └─Conv2d (0)                        [32, 128, 128, 128]  [32, 64, 128, 128]   73,792               True\n",
       "│    └─ReLU (1)                          [32, 64, 128, 128]   [32, 64, 128, 128]   --                   --\n",
       "│    └─Conv2d (2)                        [32, 64, 128, 128]   [32, 64, 128, 128]   36,928               True\n",
       "│    └─ReLU (3)                          [32, 64, 128, 128]   [32, 64, 128, 128]   --                   --\n",
       "├─Conv2d (final_conv)                    [32, 64, 128, 128]   [32, 1, 128, 128]    65                   True\n",
       "========================================================================================================================\n",
       "Total params: 24,423,809\n",
       "Trainable params: 24,423,809\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 276.23\n",
       "========================================================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 3661.63\n",
       "Params size (MB): 97.70\n",
       "Estimated Total Size (MB): 3784.49\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unet import UNet\n",
    "import torch.optim as optim\n",
    "\n",
    "model = UNet(encoder_name=\"resnet34\", in_channels=3, out_channels=1)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 256, 256), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_WORKERS = os.cpu_count()\n",
    "# print(NUM_WORKERS)\n",
    "\n",
    "# def create_dataloaders(\n",
    "#     train_dir: str,\n",
    "#     val_dir: str, \n",
    "#     test_dir: str, \n",
    "#     transform: transforms.Compose, \n",
    "#     batch_size: int, \n",
    "#     num_workers: int=NUM_WORKERS\n",
    "# ):\n",
    "#   \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "#   Takes in a training directory and testing directory path and turns\n",
    "#   them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
    "\n",
    "#   Args:\n",
    "#     train_dir: Path to training directory.\n",
    "#     test_dir: Path to testing directory.\n",
    "#     transform: torchvision transforms to perform on training and testing data.\n",
    "#     batch_size: Number of samples per batch in each of the DataLoaders.\n",
    "#     num_workers: An integer for number of workers per DataLoader.\n",
    "\n",
    "#   Returns:\n",
    "#     A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "#     Where class_names is a list of the target classes.\n",
    "#     Example usage:\n",
    "#       train_dataloader, val_dataloader, test_dataloader, class_names = \\\n",
    "#         = create_dataloaders(train_dir=path/to/train_dir,\n",
    "#                              test_dir=path/to/test_dir,\n",
    "#                              transform=some_transform,\n",
    "#                              batch_size=32,\n",
    "#                              num_workers=4)\n",
    "#   \"\"\"\n",
    "#   # Use ImageFolder to create dataset(s)\n",
    "#   train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "#   val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "#   test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "#   # Get class names\n",
    "#   class_names = train_data.classes\n",
    "\n",
    "#   # Turn images into data loaders\n",
    "#   train_dataloader = DataLoader(\n",
    "#       train_data,\n",
    "#       batch_size=batch_size,\n",
    "#       shuffle=True,\n",
    "#       num_workers=num_workers,\n",
    "#       pin_memory=True,\n",
    "#   )\n",
    "#   val_dataloader = DataLoader(\n",
    "#       val_data,\n",
    "#       batch_size=batch_size,\n",
    "#       shuffle=False,  # don't need to shuffle validation data\n",
    "#       num_workers=num_workers,\n",
    "#       pin_memory=True,\n",
    "#   )\n",
    "#   test_dataloader = DataLoader(\n",
    "#       test_data,\n",
    "#       batch_size=batch_size,\n",
    "#       shuffle=False, # don't need to shuffle test data\n",
    "#       num_workers=num_workers,\n",
    "#       pin_memory=True,\n",
    "#   )\n",
    "\n",
    "#   return train_dataloader, val_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "        transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                            std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainval_output_path = Path(\"data/Dataset_filtered/TrainVal/resized\")\n",
    "# test_output_path = Path(\"data/Dataset_filtered/Test/resized\")\n",
    "\n",
    "\n",
    "# def resize_image(original_path, output_path, resize_height=256, resize_width=256):\n",
    "\n",
    "#     # Create output directory if not exists\n",
    "#     output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Define the transformation\n",
    "#     resize_transform = transforms.Compose([\n",
    "#         transforms.Resize((resize_height, resize_width)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "#         transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "#                             std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "#     ])\n",
    "\n",
    "#     # Loop through all .jpg images and resize them\n",
    "#     for img_path in original_path.glob(\"*.jpg\"):  # Iterate over .jpg images\n",
    "#         with Image.open(img_path) as img:\n",
    "#             resized_img = resize_transform(img)  # Apply resizing\n",
    "            \n",
    "#             # Convert back to PIL image for saving\n",
    "#             resized_pil = transforms.ToPILImage()(resized_img)\n",
    "\n",
    "#             # Save resized image\n",
    "#             resized_pil.save(output_path / img_path.name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
