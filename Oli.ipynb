{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training and validation images: 3673\n",
      "Number of test images: 3694\n"
     ]
    }
   ],
   "source": [
    "image_path = Path(\"data/Dataset_filtered\")\n",
    "\n",
    "trainval_image_path = image_path / \"TrainVal/color\"\n",
    "test_image_path = image_path / \"Test/color\"\n",
    "\n",
    "trainval_jpg_count = sum(1 for file in os.listdir(trainval_image_path) if file.lower().endswith(\".jpg\"))\n",
    "print(f\"Number of training and validation images: {trainval_jpg_count}\") #3673\n",
    "\n",
    "test_jpg_count = sum(1 for file in os.listdir(test_image_path) if file.lower().endswith(\".jpg\"))\n",
    "print(f\"Number of test images: {test_jpg_count}\") #3694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Training and Validation Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def train_val_split(split_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and validation sets based on split_ratio.\n",
    "    Also updates 'train.txt' and 'val.txt' in the 'annotations' directory.\n",
    "\n",
    "    Parameters:\n",
    "        split_ratio (float): The fraction of images to be used for validation (default: 0.2)\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    base_dir = Path(\"Dataset_filtered/TrainVal\")\n",
    "    color_dir = base_dir / \"color\"\n",
    "    label_dir = base_dir / \"label\"\n",
    "\n",
    "    train_dir = Path(\"Dataset_filtered/Train\")\n",
    "    val_dir = Path(\"Dataset_filtered/Val\")\n",
    "\n",
    "    annotations_dir = Path(\"annotations\")\n",
    "    trainval_txt = annotations_dir / \"trainval.txt\"\n",
    "    train_txt = annotations_dir / \"train.txt\"\n",
    "    val_txt = annotations_dir / \"val.txt\"\n",
    "\n",
    "    # Create subdirectories if they donâ€™t exist\n",
    "    for subfolder in [\"color\", \"label\"]:\n",
    "        (train_dir / subfolder).mkdir(parents=True, exist_ok=True)\n",
    "        (val_dir / subfolder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Read the trainval.txt file\n",
    "    if not trainval_txt.exists():\n",
    "        raise FileNotFoundError(f\"trainval.txt not found in {annotations_dir}\")\n",
    "\n",
    "    with open(trainval_txt, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Extract image names (first column in trainval.txt)\n",
    "    image_names = [line.split()[0] for line in lines]  # Assuming format: \"image_name label1 label2 label3...\"\n",
    "    total_images = len(image_names)\n",
    "    val_count = int(total_images * split_ratio)\n",
    "\n",
    "    # Randomly select validation images\n",
    "    val_images = set(np.random.choice(image_names, val_count, replace=False))\n",
    "\n",
    "    # Write new train.txt and val.txt\n",
    "    with open(train_txt, \"w\") as f_train, open(val_txt, \"w\") as f_val:\n",
    "        for line in lines:\n",
    "            image_name = line.split()[0]  # Extract image name\n",
    "            if image_name in val_images:\n",
    "                f_val.write(line)\n",
    "            else:\n",
    "                f_train.write(line)\n",
    "\n",
    "    # Move images and labels to train/val folders\n",
    "    for image_name in image_names:\n",
    "        img_path = color_dir / f\"{image_name}.jpg\"\n",
    "        label_path = label_dir / f\"{image_name}.png\"  # Assuming labels are .png format\n",
    "\n",
    "        if image_name in val_images:\n",
    "            shutil.move(str(img_path), str(val_dir / \"color\" / img_path.name))\n",
    "            if label_path.exists():\n",
    "                shutil.move(str(label_path), str(val_dir / \"label\" / label_path.name))\n",
    "        else:\n",
    "            shutil.move(str(img_path), str(train_dir / \"color\" / img_path.name))\n",
    "            if label_path.exists():\n",
    "                shutil.move(str(label_path), str(train_dir / \"label\" / label_path.name))\n",
    "\n",
    "    print(f\"Dataset split completed: {total_images - val_count} training images, {val_count} validation images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Images to Make Them COnsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "NUM_WORKERS = os.cpu_count()\n",
    "print(NUM_WORKERS)\n",
    "\n",
    "def create_dataloaders(\n",
    "    train_dir: str,\n",
    "    val_dir: str, \n",
    "    test_dir: str, \n",
    "    transform: transforms.Compose, \n",
    "    batch_size: int, \n",
    "    num_workers: int=NUM_WORKERS\n",
    "):\n",
    "  \"\"\"Creates training and testing DataLoaders.\n",
    "\n",
    "  Takes in a training directory and testing directory path and turns\n",
    "  them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
    "\n",
    "  Args:\n",
    "    train_dir: Path to training directory.\n",
    "    test_dir: Path to testing directory.\n",
    "    transform: torchvision transforms to perform on training and testing data.\n",
    "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
    "    num_workers: An integer for number of workers per DataLoader.\n",
    "\n",
    "  Returns:\n",
    "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
    "    Where class_names is a list of the target classes.\n",
    "    Example usage:\n",
    "      train_dataloader, val_dataloader, test_dataloader, class_names = \\\n",
    "        = create_dataloaders(train_dir=path/to/train_dir,\n",
    "                             test_dir=path/to/test_dir,\n",
    "                             transform=some_transform,\n",
    "                             batch_size=32,\n",
    "                             num_workers=4)\n",
    "  \"\"\"\n",
    "  # Use ImageFolder to create dataset(s)\n",
    "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "  val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "  # Get class names\n",
    "  class_names = train_data.classes\n",
    "\n",
    "  # Turn images into data loaders\n",
    "  train_dataloader = DataLoader(\n",
    "      train_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=True,\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "  val_dataloader = DataLoader(\n",
    "      val_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False,  # don't need to shuffle validation data\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "  test_dataloader = DataLoader(\n",
    "      test_data,\n",
    "      batch_size=batch_size,\n",
    "      shuffle=False, # don't need to shuffle test data\n",
    "      num_workers=num_workers,\n",
    "      pin_memory=True,\n",
    "  )\n",
    "\n",
    "  return train_dataloader, val_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "        transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "                            std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainval_output_path = Path(\"data/Dataset_filtered/TrainVal/resized\")\n",
    "# test_output_path = Path(\"data/Dataset_filtered/Test/resized\")\n",
    "\n",
    "\n",
    "# def resize_image(original_path, output_path, resize_height=256, resize_width=256):\n",
    "\n",
    "#     # Create output directory if not exists\n",
    "#     output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Define the transformation\n",
    "#     resize_transform = transforms.Compose([\n",
    "#         transforms.Resize((resize_height, resize_width)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
    "#         transforms.ToTensor(), # 2. Turn image values to between 0 & 1 \n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
    "#                             std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
    "#     ])\n",
    "\n",
    "#     # Loop through all .jpg images and resize them\n",
    "#     for img_path in original_path.glob(\"*.jpg\"):  # Iterate over .jpg images\n",
    "#         with Image.open(img_path) as img:\n",
    "#             resized_img = resize_transform(img)  # Apply resizing\n",
    "            \n",
    "#             # Convert back to PIL image for saving\n",
    "#             resized_pil = transforms.ToPILImage()(resized_img)\n",
    "\n",
    "#             # Save resized image\n",
    "#             resized_pil.save(output_path / img_path.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Abyssinian_100', 'Abyssinian_101', 'Abyssinian_102', ...,\n",
       "       'yorkshire_terrier_189', 'yorkshire_terrier_18',\n",
       "       'yorkshire_terrier_190'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "\n",
    "    column_names = [\"Image\", \"CLASS-ID\", \"SPECIES\", \"BREED ID\"]\n",
    "\n",
    "    df = pd.read_csv(filename, sep=\" \", names=column_names, header=None)\n",
    "\n",
    "    return df\n",
    "\n",
    "trainval_data = read_data(\"data/annotations/trainval.txt\")\n",
    "test_data = read_data(\"data/annotations/test.txt\")\n",
    "\n",
    "trainval_data['Image'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dir = Path('data/images/cat')\n",
    "dog_dir = Path('data/images/dog')\n",
    "\n",
    "cat_dir.mkdir(parents=True, exist_ok=True)\n",
    "dog_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "valid_images = [\n",
    "    img.stem for img in Path('data/images').iterdir()\n",
    "    if img.suffix.lower() =='.jpg' \n",
    "    and (img.stem in trainval_data['Image'].values or img.stem in test_data['Image'].values)\n",
    "]\n",
    "sorted(valid_images)\n",
    "\n",
    "# cat_dir_trainval = cat_dir / 'trainval'\n",
    "# cat_dir_trainval = cat_dir / 'trainval'\n",
    "# dog_dir_trainval = dog_dir / 'trainval'\n",
    "# dog_dir_trainval = dog_dir / 'trainval'\n",
    "# cat_dir_test = cat_dir / 'test'\n",
    "# cat_dir_test = cat_dir / 'test'\n",
    "# dog_dir_test = dog_dir / 'test'\n",
    "# dog_dir_test = dog_dir / 'test'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
