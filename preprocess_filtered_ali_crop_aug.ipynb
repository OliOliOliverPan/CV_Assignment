{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1742674233437,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "AKxNh8g9eXZD"
   },
   "outputs": [],
   "source": [
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 所有图像和掩码已处理完成并保存到 train_crop 文件夹。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "input_image_dir = os.path.join(base_dir, \"train\", \"color\")\n",
    "input_mask_dir = os.path.join(base_dir, \"train\", \"label\")\n",
    "\n",
    "output_image_dir = os.path.join(base_dir, \"train_crop\", \"color\")\n",
    "output_mask_dir = os.path.join(base_dir, \"train_crop\", \"label\")\n",
    "\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "os.makedirs(output_mask_dir, exist_ok=True)\n",
    "\n",
    "# 固定裁剪参数\n",
    "crop_size = (324, 324)  # 比如 crop 后的尺寸\n",
    "crop_prob = 0.35  # 每张图 35% 概率被裁剪\n",
    "\n",
    "# 遍历所有图像\n",
    "image_filenames = sorted([f for f in os.listdir(input_image_dir) if f.endswith(\".jpg\")])\n",
    "\n",
    "for img_name in image_filenames:\n",
    "    img_path = os.path.join(input_image_dir, img_name)\n",
    "    mask_name = img_name.replace(\".jpg\", \".png\")\n",
    "    mask_path = os.path.join(input_mask_dir, mask_name)\n",
    "\n",
    "    # 打开图像和 mask\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "    # 获取原图尺寸\n",
    "    img_width, img_height = image.size\n",
    "    crop_w, crop_h = crop_size\n",
    "\n",
    "    do_crop = random.random() < crop_prob\n",
    "    use_crop = do_crop and img_width >= crop_w and img_height >= crop_h\n",
    "\n",
    "    if use_crop:\n",
    "        # 获取随机裁剪区域\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(image, output_size=crop_size)\n",
    "        image = transforms.functional.crop(image, i, j, h, w)\n",
    "        mask = transforms.functional.crop(mask, i, j, h, w)\n",
    "        # 修改文件名，标识为裁剪后的版本\n",
    "        new_img_name = os.path.splitext(img_name)[0] + \"_crop.jpg\"\n",
    "        new_mask_name = os.path.splitext(mask_name)[0] + \"_crop.png\"\n",
    "    else:\n",
    "        new_img_name = img_name\n",
    "        new_mask_name = mask_name\n",
    "\n",
    "    out_img_path = os.path.join(output_image_dir, new_img_name)\n",
    "    out_mask_path = os.path.join(output_mask_dir, new_mask_name)\n",
    "\n",
    "    image.save(out_img_path, format=\"JPEG\")\n",
    "    mask.save(out_mask_path, format=\"PNG\")\n",
    "\n",
    "print(\"✅ 所有图像和掩码已处理完成并保存到 train_crop 文件夹。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6rP4qmcWJ_"
   },
   "source": [
    "# Resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMmA-9MqcWKA"
   },
   "source": [
    "initialize一个dictionary，对每个image resize之前，记录它对应的mask的height和width并写入字典，最后将字典写入一个叫original_sizes.json的file里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1742674262860,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "oVrKiDtMcWKA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processing complete. Original sizes saved to /Users/bin/Desktop/CV_Assignment/Dataset_filtered/original_sizes.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Set target dimensions (adjust as needed)\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "target_size = (TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "\n",
    "# Create destination directories:\n",
    "# For training, we resize images but copy masks unchanged.\n",
    "resized_train_color_dir = os.path.join(base_dir, \"train_resized\", \"color\")\n",
    "resized_train_label_dir = os.path.join(base_dir, \"train_resized\", \"label\")\n",
    "\n",
    "# For validation, we resize images and copy masks unchanged.\n",
    "resized_val_color_dir = os.path.join(base_dir, \"val_resized\", \"color\")\n",
    "resized_val_label_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "\n",
    "for d in [resized_train_color_dir, resized_train_label_dir,\n",
    "          resized_val_color_dir, resized_val_label_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Dictionary to store original image sizes before resizing\n",
    "original_sizes = {}\n",
    "\n",
    "def resize_and_save(src_path, dst_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize an image and save it (don't record size here anymore).\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error reading:\", src_path)\n",
    "        return\n",
    "    resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(dst_path, resized)\n",
    "\n",
    "def process_data(color_source, label_source, resized_color_dest, resized_label_dest, original_sizes_dict):\n",
    "    \"\"\"\n",
    "    Processes a dataset split:\n",
    "    - Resizes color images and saves them.\n",
    "    - Copies label masks unchanged, and stores their original sizes with clean keys.\n",
    "    \"\"\"\n",
    "    # Resize color images\n",
    "    for filename in sorted(os.listdir(color_source)):\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            src_path = os.path.join(color_source, filename)\n",
    "            dst_path = os.path.join(resized_color_dest, filename)\n",
    "            resize_and_save(src_path, dst_path, target_size)\n",
    "\n",
    "    # Copy masks and record original sizes\n",
    "    for filename in sorted(os.listdir(label_source)):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            src_path = os.path.join(label_source, filename)\n",
    "            dst_path = os.path.join(resized_label_dest, filename)\n",
    "\n",
    "            # Load mask\n",
    "            mask = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(\"Error reading mask:\", src_path)\n",
    "                continue\n",
    "\n",
    "            # 🔥 Clean filename key: remove suffix like \".png\"\n",
    "            img_key = os.path.splitext(filename)[0]  # \"Abyssinian_1.png\" → \"Abyssinian_1\"\n",
    "            original_sizes_dict[img_key] = list(mask.shape)  # Ensure JSON serializable: [H, W]\n",
    "\n",
    "            # Copy mask as-is\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Process Training Data\n",
    "# -----------------------------------------\n",
    "train_color_source = os.path.join(base_dir, \"train_crop\", \"color\")\n",
    "train_label_source = os.path.join(base_dir, \"train_crop\", \"label\")\n",
    "\n",
    "process_data(train_color_source, train_label_source, resized_train_color_dir, resized_train_label_dir, original_sizes)\n",
    "\n",
    "# # -----------------------------------------\n",
    "# # Process Validation Data\n",
    "# # -----------------------------------------\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "val_color_source = os.path.join(val_dir, \"color\")\n",
    "val_label_source = os.path.join(val_dir, \"label\")\n",
    "\n",
    "process_data(val_color_source, val_label_source, resized_val_color_dir, resized_val_label_dir, original_sizes)\n",
    "\n",
    "# Save original sizes to a JSON file\n",
    "original_size_json_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "with open(original_size_json_path, \"w\") as f:\n",
    "    json.dump(original_sizes, f, indent=4)\n",
    "\n",
    "print(f\"✅ Processing complete. Original sizes saved to {original_size_json_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EKuuM-NcWKB"
   },
   "source": [
    "将images和masks都写入DataLoader里，但同时也要记录每张image的name以便后面查询mask的original size\n",
    "除此以外，对于mask tensor化的操作还要更改。我们目前有5个class:[cat, dog, background, boundary, unknown] 分别对应class 0,1,2,3,4,我们通过默认的transforms.ToTensor()使得mask的每个tensor的每个像素都变为该像素的值后，我们还要进一步操作:对于每个tensor值，如果是0，就把该值变为2（意为background),如果是1，就把这个值变为3（意为boundary),如果是介于0-1之间的值，我们看这个mask的filename，如果filename的第一个字母是大写，将该值变为0(意为猫),反之如果是小写，就变成1（意为狗),如果是图片变小了，有些区域不属于原始图片，我们标为4（意为unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC_DYSv0lEhj"
   },
   "source": [
    "treat boundary as a new class: boundary for now. currently we have 5 classes: [cat, dog, boundary, background, unknown]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------\n",
    "# Process Test Data\n",
    "# -----------------------------------------\n",
    "\n",
    "# Directories\n",
    "test_dir = os.path.join(base_dir, \"Test\")\n",
    "resized_test_color_dir = os.path.join(base_dir, \"test_resized\", \"color\")\n",
    "resized_test_label_dir = os.path.join(base_dir, \"test_resized\", \"label\")\n",
    "\n",
    "# Create folders\n",
    "os.makedirs(resized_test_color_dir, exist_ok=True)\n",
    "os.makedirs(resized_test_label_dir, exist_ok=True)\n",
    "\n",
    "# Dictionary for test original sizes\n",
    "original_sizes_test = {}\n",
    "\n",
    "# Source folders\n",
    "test_color_source = os.path.join(test_dir, \"color\")\n",
    "test_label_source = os.path.join(test_dir, \"label\")\n",
    "\n",
    "# Process test data\n",
    "process_data(\n",
    "    color_source=test_color_source,\n",
    "    label_source=test_label_source,\n",
    "    resized_color_dest=resized_test_color_dir,\n",
    "    resized_label_dest=resized_test_label_dir,\n",
    "    original_sizes_dict=original_sizes_test\n",
    ")\n",
    "\n",
    "# Save test sizes JSON\n",
    "test_size_json_path = os.path.join(base_dir, \"original_sizes_test.json\")\n",
    "with open(test_size_json_path, \"w\") as f:\n",
    "    json.dump(original_sizes_test, f, indent=4)\n",
    "\n",
    "print(f\"✅ Test data processed. Test mask sizes saved to {test_size_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex, Dice\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from unet import UNet\n",
    "from custom_dataset import CustomDataset\n",
    "from enhanced_unet import EnhancedUNet\n",
    "\n",
    "# === Config ===\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = [\"Cat\", \"Dog\", \"Background\", \"Boundary\"]\n",
    "\n",
    "MODEL_PATH = '/Users/bin/Desktop/CV_Assignment/Model/best_unet_100_epochs_baseline.pth'\n",
    "original_sizes_path = os.path.join(base_dir, \"original_sizes_test.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load model ===\n",
    "model = EnhancedUNet(in_channels=3, out_channels=NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === Load original sizes ===\n",
    "with open(original_sizes_path, \"r\") as f:\n",
    "    original_sizes = json.load(f)\n",
    "\n",
    "# === Load test dataset ===\n",
    "test_dataset = CustomDataset(\n",
    "    image_dir=os.path.join(base_dir, \"test_resized\", \"color\"),\n",
    "    mask_dir=os.path.join(base_dir, \"test_resized\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# === Metrics ===\n",
    "iou_metric = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\").to(device)\n",
    "dice_metric = Dice(num_classes=NUM_CLASSES, average=\"none\").to(device)\n",
    "\n",
    "# === Evaluation loop ===\n",
    "with torch.no_grad():\n",
    "    for image, mask, img_name, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        mask = mask.squeeze(0).to(device).long()  # (H, W) with values 0~3\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(image)  # (1, 4, 256, 256)\n",
    "\n",
    "        # Resize logits to original size before argmax\n",
    "        orig_h, orig_w = original_sizes[img_name[0]]\n",
    "        logits_resized = F.interpolate(logits, size=(orig_h, orig_w), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Apply argmax AFTER resizing\n",
    "        pred_mask = torch.argmax(logits_resized, dim=1).long()  # (1, H, W)\n",
    "\n",
    "        # Resize GT mask (if needed) just in case\n",
    "        gt_resized = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=(orig_h, orig_w), mode=\"nearest\").squeeze(0).long()\n",
    "\n",
    "        # Update metrics\n",
    "        iou_metric.update(pred_mask.to(device), gt_resized.to(device))\n",
    "        dice_metric.update(pred_mask.to(device), gt_resized.to(device))\n",
    "\n",
    "# === Compute final results ===\n",
    "iou_scores = iou_metric.compute()\n",
    "dice_scores = dice_metric.compute()\n",
    "\n",
    "# === Print Results ===\n",
    "print(\"\\n📊 Per-Class Evaluation on Test Set:\")\n",
    "for i in range(NUM_CLASSES):\n",
    "    print(f\"Class {i} ({CLASS_NAMES[i]}): IoU = {iou_scores[i]:.4f}, Dice = {dice_scores[i]:.4f}\")\n",
    "\n",
    "mean_iou = iou_scores.mean()\n",
    "mean_dice = dice_scores.mean()\n",
    "print(f\"\\n➡️ Mean IoU of all classes: {mean_iou:.4f}\")\n",
    "print(f\"➡️ Mean Dice of all classes: {mean_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex#, Dice\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from unet import UNet\n",
    "from custom_dataset import CustomDataset\n",
    "from enhanced_unet import EnhancedUNet\n",
    "\n",
    "# === Config ===\n",
    "NUM_CLASSES = 4\n",
    "# 我们只关注 0:Cat, 1:Dog, 2:Background，忽略 3:Boundary（不参与指标计算）\n",
    "CLASS_NAMES = [\"Cat\", \"Dog\", \"Background\", \"Boundary\"]\n",
    "\n",
    "MODEL_PATH = '/Users/bin/Desktop/CV_Assignment/Model/best_enhanced_unet_100_epochs.pth'\n",
    "original_sizes_path = os.path.join(base_dir, \"original_sizes_test.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load model ===\n",
    "model = EnhancedUNet(in_channels=3, out_channels=NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === Load original sizes ===\n",
    "with open(original_sizes_path, \"r\") as f:\n",
    "    original_sizes = json.load(f)\n",
    "\n",
    "# === Load test dataset ===\n",
    "test_dataset = CustomDataset(\n",
    "    image_dir=os.path.join(base_dir, \"test_resized\", \"color\"),\n",
    "    mask_dir=os.path.join(base_dir, \"test_resized\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# === Metrics ===\n",
    "# 注意：这里设置 ignore_index=3，表示在计算时忽略 ground truth 中标签为3的像素\n",
    "iou_metric = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\", ignore_index=3).to(device)\n",
    "#dice_metric = Dice(num_classes=NUM_CLASSES, average=\"none\", ignore_index=3).to(device)\n",
    "\n",
    "# === Evaluation loop ===\n",
    "with torch.no_grad():\n",
    "    for image, mask, img_name, _ in tqdm(test_loader):\n",
    "        image = image.to(device)\n",
    "        # mask: (H, W) with values 0~3, convert to long tensor\n",
    "        mask = mask.squeeze(0).to(device).long()\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(image)  # (1, 4, 256, 256)\n",
    "\n",
    "        # Resize logits to original size before argmax\n",
    "        orig_h, orig_w = original_sizes[img_name[0]]\n",
    "        logits_resized = F.interpolate(logits, size=(orig_h, orig_w), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "        # Apply argmax AFTER resizing\n",
    "        pred_mask = torch.argmax(logits_resized, dim=1).long()  # (1, H, W)\n",
    "\n",
    "        # Resize GT mask to original size if needed\n",
    "        gt_resized = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=(orig_h, orig_w), mode=\"nearest\").squeeze(0).long()\n",
    "\n",
    "        # Update metrics; pixels where gt == 3 are ignored automatically\n",
    "        iou_metric.update(pred_mask.to(device), gt_resized.to(device))\n",
    "        #dice_metric.update(pred_mask.to(device), gt_resized.to(device))\n",
    "\n",
    "# === Compute final results ===\n",
    "iou_scores = iou_metric.compute()  # 返回 shape (num_classes,) ，其中 ignore_index=3 不会计入结果\n",
    "#dice_scores = dice_metric.compute()\n",
    "\n",
    "# 仅输出类别 0,1,2 的指标\n",
    "print(\"\\n📊 Per-Class Evaluation on Test Set (excluding class 3):\")\n",
    "for i in range(3):\n",
    "    print(f\"Class {i} ({CLASS_NAMES[i]}): IoU = {iou_scores[i]:.4f}\")#, Dice = {dice_scores[i]:.4f}\")\n",
    "\n",
    "# 计算 mean IoU / Dice，只考虑 class 0,1,2\n",
    "mean_iou = iou_scores[:3].mean()\n",
    "# mean_dice = dice_scores[:3].mean()\n",
    "print(f\"\\n➡️ Mean IoU of classes 0-2: {mean_iou:.4f}\")\n",
    "# print(f\"➡️ Mean Dice of classes 0-2: {mean_dice:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
