{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1742674233437,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "AKxNh8g9eXZD"
   },
   "outputs": [],
   "source": [
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29367,
     "status": "ok",
     "timestamp": 1742674262762,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "d5pNrLzodT_7",
    "outputId": "b7a87a82-a418-452c-d202-651df541def9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AijK3ImLcWJ8"
   },
   "source": [
    "# split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742674262783,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "n1ZSBTrFcWJ9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Set seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "def trainval_split(base_dir):\n",
    "\n",
    "    # Define base directories\n",
    "    trainval_dir = os.path.join(base_dir, \"TrainVal\")\n",
    "    color_dir = os.path.join(trainval_dir, \"color\")\n",
    "    label_dir = os.path.join(trainval_dir, \"label\")\n",
    "\n",
    "    # Define destination directories for train and validation splits\n",
    "    train_color_dir = os.path.join(base_dir, \"train\", \"color\")\n",
    "    train_label_dir = os.path.join(base_dir, \"train\", \"label\")\n",
    "    val_color_dir = os.path.join(base_dir, \"val\", \"color\")\n",
    "    val_label_dir = os.path.join(base_dir, \"val\", \"label\")\n",
    "\n",
    "    # Create the destination directories if they don't exist\n",
    "    for d in [train_color_dir, train_label_dir, val_color_dir, val_label_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    # Find all jpg files in the color folder\n",
    "    image_files = glob.glob(os.path.join(color_dir, \"*.jpg\"))\n",
    "\n",
    "    # Group files by animal name (assumes format like \"Abyssinian_1.jpg\")\n",
    "    groups = {}\n",
    "    pattern = re.compile(r'(.+)_\\d+\\.jpg')  # capture group for the animal name\n",
    "    for image_file in image_files:\n",
    "        basename = os.path.basename(image_file)\n",
    "        match = pattern.match(basename)\n",
    "        if match:\n",
    "            animal = match.group(1)\n",
    "        else:\n",
    "            animal = \"unknown\"\n",
    "        groups.setdefault(animal, []).append(basename)\n",
    "\n",
    "    # Split the files for each animal into train (80%) and val (20%)\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    for animal, files in groups.items():\n",
    "        random.shuffle(files)\n",
    "        split_index = int(0.8 * len(files))\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "        train_list.extend(train_files)\n",
    "        val_list.extend(val_files)\n",
    "\n",
    "    # Define output text file paths\n",
    "    train_txt_path = os.path.join(base_dir, \"train.txt\")\n",
    "    val_txt_path = os.path.join(base_dir, \"val.txt\")\n",
    "\n",
    "    # Copy files to new folders and write paths to train.txt and val.txt\n",
    "    with open(train_txt_path, \"w\") as train_file, open(val_txt_path, \"w\") as val_file:\n",
    "        # Process train split\n",
    "        for filename in train_list:\n",
    "            # Copy color image\n",
    "            src_color = os.path.join(color_dir, filename)\n",
    "            dst_color = os.path.join(train_color_dir, filename)\n",
    "            shutil.copy2(src_color, dst_color)\n",
    "\n",
    "            # Derive corresponding label filename (change extension from .jpg to .png)\n",
    "            label_filename = filename.replace(\".jpg\", \".png\")\n",
    "            src_label = os.path.join(label_dir, label_filename)\n",
    "            dst_label = os.path.join(train_label_dir, label_filename)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "            # Write relative paths to train.txt (format: \"train/color/<filename> train/label/<label_filename>\")\n",
    "            train_file.write(f\"{os.path.join('train','color',filename)} {os.path.join('train','label',label_filename)}\\n\")\n",
    "\n",
    "        # Process validation split\n",
    "        for filename in val_list:\n",
    "            # Copy color image\n",
    "            src_color = os.path.join(color_dir, filename)\n",
    "            dst_color = os.path.join(val_color_dir, filename)\n",
    "            shutil.copy2(src_color, dst_color)\n",
    "\n",
    "            # Corresponding label filename\n",
    "            label_filename = filename.replace(\".jpg\", \".png\")\n",
    "            src_label = os.path.join(label_dir, label_filename)\n",
    "            dst_label = os.path.join(val_label_dir, label_filename)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "            # Write relative paths to val.txt\n",
    "            val_file.write(f\"{os.path.join('val','color',filename)} {os.path.join('val','label',label_filename)}\\n\")\n",
    "\n",
    "    print(\"Data splitting and copying complete.\")\n",
    "    print(f\"Train list written to {train_txt_path}\")\n",
    "    print(f\"Val list written to {val_txt_path}\")\n",
    "\n",
    "# trainval_split(base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6rP4qmcWJ_"
   },
   "source": [
    "# Resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMmA-9MqcWKA"
   },
   "source": [
    "initialize‰∏Ä‰∏™dictionaryÔºåÂØπÊØè‰∏™image resize‰πãÂâçÔºåËÆ∞ÂΩïÂÆÉÂØπÂ∫îÁöÑmaskÁöÑheightÂíåwidthÂπ∂ÂÜôÂÖ•Â≠óÂÖ∏ÔºåÊúÄÂêéÂ∞ÜÂ≠óÂÖ∏ÂÜôÂÖ•‰∏Ä‰∏™Âè´original_sizes.jsonÁöÑfileÈáå"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1742674262860,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "oVrKiDtMcWKA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Set target dimensions (adjust as needed)\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "target_size = (TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "# Directories for train and val splits\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "\n",
    "# Create destination directories:\n",
    "# For training, we resize images but copy masks unchanged.\n",
    "resized_train_color_dir = os.path.join(base_dir, \"train_resized\", \"color\")\n",
    "resized_train_label_dir = os.path.join(base_dir, \"train_resized\", \"label\")\n",
    "\n",
    "# For validation, we resize images and copy masks unchanged.\n",
    "resized_val_color_dir = os.path.join(base_dir, \"val_resized\", \"color\")\n",
    "resized_val_label_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "\n",
    "for d in [resized_train_color_dir, resized_train_label_dir,\n",
    "          resized_val_color_dir, resized_val_label_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Dictionary to store original image sizes before resizing\n",
    "original_sizes = {}\n",
    "\n",
    "def resize_and_save(src_path, dst_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize an image and save it (don't record size here anymore).\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error reading:\", src_path)\n",
    "        return\n",
    "    resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(dst_path, resized)\n",
    "\n",
    "def process_data(color_source, label_source, resized_color_dest, resized_label_dest, original_sizes_dict):\n",
    "    \"\"\"\n",
    "    Processes a dataset split:\n",
    "    - Resizes color images and saves them.\n",
    "    - Copies label masks unchanged, and stores their original sizes with clean keys.\n",
    "    \"\"\"\n",
    "    # Resize color images\n",
    "    for filename in sorted(os.listdir(color_source)):\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            src_path = os.path.join(color_source, filename)\n",
    "            dst_path = os.path.join(resized_color_dest, filename)\n",
    "            resize_and_save(src_path, dst_path, target_size)\n",
    "\n",
    "    # Copy masks and record original sizes\n",
    "    for filename in sorted(os.listdir(label_source)):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            src_path = os.path.join(label_source, filename)\n",
    "            dst_path = os.path.join(resized_label_dest, filename)\n",
    "\n",
    "            # Load mask\n",
    "            mask = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(\"Error reading mask:\", src_path)\n",
    "                continue\n",
    "\n",
    "            # üî• Clean filename key: remove suffix like \".png\"\n",
    "            img_key = os.path.splitext(filename)[0]  # \"Abyssinian_1.png\" ‚Üí \"Abyssinian_1\"\n",
    "            original_sizes_dict[img_key] = list(mask.shape)  # Ensure JSON serializable: [H, W]\n",
    "\n",
    "            # Copy mask as-is\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Process Training Data\n",
    "# -----------------------------------------\n",
    "train_color_source = os.path.join(train_dir, \"color\")\n",
    "train_label_source = os.path.join(train_dir, \"label\")\n",
    "\n",
    "# process_data(train_color_source, train_label_source, resized_train_color_dir, resized_train_label_dir, original_sizes)\n",
    "\n",
    "# # -----------------------------------------\n",
    "# # Process Validation Data\n",
    "# # -----------------------------------------\n",
    "val_color_source = os.path.join(val_dir, \"color\")\n",
    "val_label_source = os.path.join(val_dir, \"label\")\n",
    "\n",
    "# process_data(val_color_source, val_label_source, resized_val_color_dir, resized_val_label_dir, original_sizes)\n",
    "\n",
    "# Save original sizes to a JSON file\n",
    "original_size_json_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "with open(original_size_json_path, \"w\") as f:\n",
    "    json.dump(original_sizes, f, indent=4)\n",
    "\n",
    "# print(f\"‚úÖ Processing complete. Original sizes saved to {original_size_json_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN2nCJwScWKB"
   },
   "source": [
    "# randaugment (Do the augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1742674262861,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "-6bFQ4ohcWKB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import math\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# Define the RandAugment operation pool (14 ops as in the original paper)\n",
    "RA_OPERATIONS = [\n",
    "    \"Identity\", \"AutoContrast\", \"Equalize\",\n",
    "    \"Rotate\", \"Solarize\", \"Color\", \"Posterize\",\n",
    "    \"Contrast\", \"Brightness\", \"Sharpness\",\n",
    "    \"ShearX\", \"ShearY\", \"TranslateX\", \"TranslateY\"\n",
    "]\n",
    "\n",
    "def apply_operation(img, mask, op_name, magnitude):\n",
    "    \"\"\"\n",
    "    Apply a single augmentation operation to the image (and mask, if applicable).\n",
    "    'magnitude' is on a 0-10 scale indicating severity.\n",
    "    \"\"\"\n",
    "    if op_name == \"Identity\":\n",
    "        return img, mask  # no change\n",
    "\n",
    "    if op_name == \"AutoContrast\":\n",
    "        img = ImageOps.autocontrast(img)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Equalize\":\n",
    "        img = ImageOps.equalize(img)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Rotate\":\n",
    "        max_deg = 30.0\n",
    "        angle = magnitude / 10.0 * max_deg\n",
    "        if random.random() < 0.5:\n",
    "            angle = -angle\n",
    "        img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "        mask = mask.rotate(angle, resample=Image.NEAREST, fillcolor=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Solarize\":\n",
    "        thresh = int(256 - (magnitude / 10.0) * 256)\n",
    "        img = ImageOps.solarize(img, thresh)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Color\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Color(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Posterize\":\n",
    "        bits = int(round(8 - (magnitude / 10.0) * 4))\n",
    "        bits = max(1, bits)\n",
    "        img = ImageOps.posterize(img, bits)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Contrast\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Contrast(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Brightness\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Brightness(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Sharpness\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Sharpness(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    # Geometric operations: these need to be applied identically to the mask\n",
    "    if op_name == \"ShearX\":\n",
    "        shear_factor = magnitude / 10.0 * 0.3\n",
    "        if random.random() < 0.5:\n",
    "            shear_factor = -shear_factor\n",
    "        shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "        img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                       shear=(shear_degrees, 0.0),\n",
    "                       interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                        shear=(shear_degrees, 0.0),\n",
    "                        interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"ShearY\":\n",
    "        shear_factor = magnitude / 10.0 * 0.3\n",
    "        if random.random() < 0.5:\n",
    "            shear_factor = -shear_factor\n",
    "        shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "        img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                       shear=(0.0, shear_degrees),\n",
    "                       interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                        shear=(0.0, shear_degrees),\n",
    "                        interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"TranslateX\":\n",
    "        max_frac = 0.45\n",
    "        dx = int(round(magnitude / 10.0 * max_frac * img.width))\n",
    "        if random.random() < 0.5:\n",
    "            dx = -dx\n",
    "        img = F.affine(img, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "                       shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "                        shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"TranslateY\":\n",
    "        max_frac = 0.45\n",
    "        dy = int(round(magnitude / 10.0 * max_frac * img.height))\n",
    "        if random.random() < 0.5:\n",
    "            dy = -dy\n",
    "        img = F.affine(img, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "                       shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "                        shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "def randaugment_image_mask(img, mask, N, M):\n",
    "    \"\"\"Apply RandAugment (N operations with magnitude M) to the given PIL image and mask.\"\"\"\n",
    "    ops = random.sample(RA_OPERATIONS, N)  # choose N distinct ops at random\n",
    "    for op in ops:\n",
    "        img, mask = apply_operation(img, mask, op, M)\n",
    "    return img, mask\n",
    "\n",
    "def run_randaugment_train_resized(input_base, output_base, N=2, M=9, num_aug=3):\n",
    "    \"\"\"\n",
    "    Process each image-mask pair from the resized training data.\n",
    "\n",
    "    Expects:\n",
    "      - Images in:  input_base/train_resized/color\n",
    "      - Masks in:   input_base/train_resized/label\n",
    "\n",
    "    Saves augmented outputs in:\n",
    "      - output_base/train_randaugmented/color\n",
    "      - output_base/train_randaugmented/label\n",
    "\n",
    "    Additionally, copies the original image and mask.\n",
    "    Generates 'num_aug' augmented images per original image.\n",
    "    \"\"\"\n",
    "    in_img_dir = os.path.join(input_base, \"train_resized\", \"color\")\n",
    "    in_mask_dir = os.path.join(input_base, \"train_resized\", \"label\")\n",
    "    out_img_dir = os.path.join(output_base, \"train_randaugmented\", \"color\")\n",
    "    out_mask_dir = os.path.join(output_base, \"train_randaugmented\", \"label\")\n",
    "    os.makedirs(out_img_dir, exist_ok=True)\n",
    "    os.makedirs(out_mask_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(in_img_dir):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "        img_path = os.path.join(in_img_dir, filename)\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        # Try common mask extensions (often masks are stored as .png)\n",
    "        mask_candidates = [base_name + \".png\", base_name + \".jpg\", base_name + \".jpeg\", base_name + \".bmp\", base_name + \".tif\"]\n",
    "        mask_path = None\n",
    "        for cand in mask_candidates:\n",
    "            cand_path = os.path.join(in_mask_dir, cand)\n",
    "            if os.path.exists(cand_path):\n",
    "                mask_path = cand_path\n",
    "                break\n",
    "        if mask_path is None:\n",
    "            print(f\"Mask for image {filename} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "        if mask.mode not in [\"L\", \"I\"]:\n",
    "            mask = mask.convert(\"L\")\n",
    "\n",
    "        # Save the original image and mask in the output folders\n",
    "        orig_img_path = os.path.join(out_img_dir, f\"{base_name}_orig.jpg\")\n",
    "        orig_mask_path = os.path.join(out_mask_dir, f\"{base_name}_orig.png\")\n",
    "        img.save(orig_img_path)\n",
    "        mask.save(orig_mask_path)\n",
    "        print(f\"Saved original image to {orig_img_path} and mask to {orig_mask_path}\")\n",
    "\n",
    "        # Generate and save augmented versions\n",
    "        for i in range(num_aug):\n",
    "            aug_img, aug_mask = randaugment_image_mask(img, mask, N, M)\n",
    "            out_img_path = os.path.join(out_img_dir, f\"{base_name}_aug_{i}.jpg\")\n",
    "            out_mask_path = os.path.join(out_mask_dir, f\"{base_name}_aug_{i}.png\")\n",
    "            aug_img.save(out_img_path)\n",
    "            aug_mask.save(out_mask_path)\n",
    "            print(f\"Saved augmented image to {out_img_path} and mask to {out_mask_path}\")\n",
    "\n",
    "# --- Example usage in a notebook cell ---\n",
    "# Set your base directory. In your case, it is:\n",
    "# We'll use the same base directory for output (augmented data will be saved under a new subfolder)\n",
    "# run_randaugment_train_resized(base_dir, base_dir, N=2, M=9, num_aug=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EKuuM-NcWKB"
   },
   "source": [
    "Â∞ÜimagesÂíåmasksÈÉΩÂÜôÂÖ•DataLoaderÈáåÔºå‰ΩÜÂêåÊó∂‰πüË¶ÅËÆ∞ÂΩïÊØèÂº†imageÁöÑname‰ª•‰æøÂêéÈù¢Êü•ËØ¢maskÁöÑoriginal size\n",
    "Èô§Ê≠§‰ª•Â§ñÔºåÂØπ‰∫émask tensorÂåñÁöÑÊìç‰ΩúËøòË¶ÅÊõ¥Êîπ„ÄÇÊàë‰ª¨ÁõÆÂâçÊúâ4‰∏™class:[cat, dog, background, boundary] ÂàÜÂà´ÂØπÂ∫îclass 0,1,2,3,Êàë‰ª¨ÈÄöËøáÈªòËÆ§ÁöÑtransforms.ToTensor()‰ΩøÂæómaskÁöÑÊØè‰∏™tensorÁöÑÊØè‰∏™ÂÉèÁ¥†ÈÉΩÂèò‰∏∫ËØ•ÂÉèÁ¥†ÁöÑÂÄºÂêéÔºåÊàë‰ª¨ËøòË¶ÅËøõ‰∏ÄÊ≠•Êìç‰Ωú:ÂØπ‰∫éÊØè‰∏™tensorÂÄºÔºåÂ¶ÇÊûúÊòØ0ÔºåÂ∞±ÊääËØ•ÂÄºÂèò‰∏∫2ÔºàÊÑè‰∏∫background),Â¶ÇÊûúÊòØ1ÔºåÂ∞±ÊääËøô‰∏™ÂÄºÂèò‰∏∫3ÔºàÊÑè‰∏∫boundary),Â¶ÇÊûúÊòØ‰ªã‰∫é0-1‰πãÈó¥ÁöÑÂÄºÔºåÊàë‰ª¨ÁúãËøô‰∏™maskÁöÑfilenameÔºåÂ¶ÇÊûúfilenameÁöÑÁ¨¨‰∏Ä‰∏™Â≠óÊØçÊòØÂ§ßÂÜôÔºåÂ∞ÜËØ•ÂÄºÂèò‰∏∫0(ÊÑè‰∏∫Áå´),Âèç‰πãÂ¶ÇÊûúÊòØÂ∞èÂÜôÔºåÂ∞±ÂèòÊàê1ÔºàÊÑè‰∏∫Áãó)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 38043,
     "status": "ok",
     "timestamp": 1742674300889,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "4fDV4BMmcWKB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique class indices and pixel counts:\n",
      "Class 1: 17542 pixels\n",
      "Class 2: 36833 pixels\n",
      "Class 3: 5925 pixels\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from drive.MyDrive.CV_Assignment.custom_dataset import CustomDataset\n",
    "from custom_dataset import CustomDataset\n",
    "# Create dataset\n",
    "dataset = CustomDataset(\n",
    "    image_dir = os.path.join(base_dir, \"train_randaugmented\", \"color\"),\n",
    "    mask_dir = os.path.join(base_dir, \"train_randaugmented\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Custom collate function to handle filenames\n",
    "def custom_collate_fn(batch):\n",
    "    images, masks, img_names, mask_names = zip(*batch)\n",
    "\n",
    "    img_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in img_names]\n",
    "    mask_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in mask_names]\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    # masks = torch.stack(masks)\n",
    "    return images, list(masks), list(img_names), list(mask_names)\n",
    "\n",
    "# Create DataLoader with shuffle=True but keeping filenames\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Test DataLoader\n",
    "# for images, masks, img_names, mask_names in train_dataloader:\n",
    "#     print(\"Batch Image Filenames:\", img_names)\n",
    "#     print(\"Batch Mask Filenames:\", mask_names)\n",
    "#     break\n",
    "\n",
    "# ÂèñÁ¨¨‰∏Ä‰∏™ batch\n",
    "# first_batch = next(iter(train_dataloader))\n",
    "\n",
    "# # Ëß£ÂåÖ batch ÂÜÖÂÆπ\n",
    "# images, masks, img_names, mask_names = first_batch\n",
    "\n",
    "# # ÂèñÁ¨¨‰∏Ä‰∏™Êé©ËÜú\n",
    "# first_mask = masks[0]  # LongTensor, shape: (H, W)\n",
    "\n",
    "# # Êü•ÁúãÂîØ‰∏ÄÁ±ªÂà´Ê†áÁ≠æÂèäÂÖ∂ÂÉèÁ¥†Êï∞Èáè\n",
    "# unique_classes, counts = torch.unique(first_mask, return_counts=True)\n",
    "# print(\"Unique class indices and pixel counts:\")\n",
    "# for cls, count in zip(unique_classes.tolist(), counts.tolist()):\n",
    "#     print(f\"Class {cls}: {count} pixels\")\n",
    "\n",
    "# # ÂèØËßÜÂåñÊé©ËÜú\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(first_mask, cmap=\"gray\")\n",
    "# plt.title(f\"Mask: {mask_names[0]}\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define path and list mask files\n",
    "mask_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "mask_files = [f for f in os.listdir(mask_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Step 2: Pick a random file\n",
    "random_mask_file = random.choice(mask_files)\n",
    "mask_path = os.path.join(mask_dir, random_mask_file)\n",
    "\n",
    "# Step 3: Open the image (no conversion)\n",
    "mask = Image.open(mask_path)\n",
    "\n",
    "# Step 4: Convert to tensor\n",
    "mask_tensor = transforms.ToTensor()(mask)  # Shape: (C, H, W)\n",
    "\n",
    "print(f\"Loaded mask: {random_mask_file}\")\n",
    "print(f\"Tensor shape: {mask_tensor.shape}\")\n",
    "\n",
    "# Step 5: Find unique pixel values\n",
    "if mask_tensor.ndim == 3 and mask_tensor.shape[0] == 3:  # RGB\n",
    "    pixels = mask_tensor.view(3, -1).permute(1, 0)  # shape: (H*W, 3)\n",
    "    pixels = torch.round(pixels * 255).to(torch.uint8)\n",
    "    unique_colors, counts = torch.unique(pixels, return_counts=True, dim=0)\n",
    "\n",
    "    print(\"Unique RGB pixel values and their counts:\")\n",
    "    for color, count in zip(unique_colors, counts):\n",
    "        print(f\"{color.tolist()} --> {count.item()} pixels\")\n",
    "\n",
    "else:  # Grayscale or single-channel\n",
    "    mask_flat = mask_tensor.view(-1)\n",
    "    unique_values, counts = torch.unique(mask_flat, return_counts=True)\n",
    "\n",
    "    print(\"Unique grayscale pixel values and their counts:\")\n",
    "    for val, count in zip(unique_values, counts):\n",
    "        print(f\"{val.item():.6f} --> {count.item()} pixels\")\n",
    "\n",
    "# Step 6: Display the mask image\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(f\"Random Mask: {random_mask_file}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31562,
     "status": "ok",
     "timestamp": 1742674332449,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "tvPYU-cKcWKC",
    "outputId": "3db85f9f-9c9d-469d-882e-575bab7c9ff4"
   },
   "outputs": [],
   "source": [
    "# from drive.MyDrive.CV_Assignment.unet import UNet\n",
    "# import torch.optim as optim\n",
    "\n",
    "# model = UNet(in_channels=3, out_channels=4)\n",
    "\n",
    "# # Move model to GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# x = torch.randn(32, 3, 256, 256)  # Example input tensor\n",
    "# output = model(x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCZi4DnccWKC",
    "outputId": "0d3860fb-d4d8-4a92-b455-275f230f08c6"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def resize_multiclass_logits(logits, img_names, original_sizes_dict):\n",
    "    resized_logits = []\n",
    "    for i in range(len(logits)):\n",
    "        name = img_names[i]\n",
    "        orig_h, orig_w = original_sizes_dict[name]\n",
    "        resized = F.interpolate(\n",
    "            logits[i].unsqueeze(0),  # shape (1, 4, 256, 256)\n",
    "            size=(orig_h, orig_w),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        resized_logits.append(resized.squeeze(0))  # shape: (4, H, W)\n",
    "    return resized_logits  # list of tensors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(base_dir, \"original_sizes.json\"), \"r\") as f:\n",
    "    original_sizes_dict = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "PRINT_INTERVAL = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop over multiple epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for images, masks, img_names, mask_names in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = [m.to(device) for m in masks]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1Ô∏è‚É£ Forward pass ‚Äî output shape: (B, 4, 256, 256)\n",
    "        logits = model(images)\n",
    "\n",
    "        # 2Ô∏è‚É£ Resize each predicted logits map to original mask size\n",
    "        resized_logits = resize_multiclass_logits(logits, img_names, original_sizes_dict)  # List of (4, H, W)\n",
    "\n",
    "        # 3Ô∏è‚É£ Compute per-sample loss (cross entropy expects (C, H, W) + (H, W))\n",
    "        total_loss = 0\n",
    "        for pred_logits, gt_mask in zip(resized_logits, masks):\n",
    "          # Add batch dimension to both tensors\n",
    "          pred_logits = pred_logits.unsqueeze(0)  # shape: (1, 4, H, W)\n",
    "          gt_mask = gt_mask.unsqueeze(0)          # shape: (1, H, W)\n",
    "\n",
    "          loss = loss_fn(pred_logits, gt_mask)\n",
    "          total_loss += loss\n",
    "\n",
    "        # 5Ô∏è‚É£ Backward + update\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % PRINT_INTERVAL == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"üéâ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the predicted mask of a random image from val_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define your model architecture ---\n",
    "# Dummy example: Replace with your actual UNet model class\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 2. Load model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_channels=3, out_channels=4).to(device)\n",
    "model.load_state_dict(torch.load(\"/Users/bin/Desktop/CV_Assignment/Model/unet_100_epochs.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === 3. Load original size dictionary ===\n",
    "with open(\"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/original_sizes.json\", \"r\") as f:\n",
    "    original_sizes = json.load(f)\n",
    "\n",
    "# === 4. Load and transform image ===\n",
    "val_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/val_resized/color\"\n",
    "img_names = sorted(os.listdir(val_dir))\n",
    "img_name = random.choice(img_names)\n",
    "img_path = os.path.join(val_dir, img_name)\n",
    "img_key = os.path.splitext(img_name)[0]\n",
    "\n",
    "print(f\"Predicting on image: {img_name}\")\n",
    "\n",
    "# Resize transform (same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)  # shape: (1, 3, 256, 256)\n",
    "\n",
    "# === 5. Predict logits ===\n",
    "with torch.no_grad():\n",
    "    logits = model(image_tensor)  # shape: (1, 4, 256, 256)\n",
    "    pred_class = torch.argmax(logits, dim=1, keepdim=True)  # shape: (1, 1, 256, 256)\n",
    "\n",
    "    # === 6. Resize predicted mask back to original size ===\n",
    "    orig_h, orig_w = original_sizes[img_key]\n",
    "    pred_resized = torch.nn.functional.interpolate(pred_class.float(), size=(orig_h, orig_w), mode=\"nearest\")  # shape: (1, 1, H, W)\n",
    "    print(\"Unique predicted class values:\", torch.unique(pred_resized))\n",
    "    final_mask = pred_resized.squeeze().cpu().long()  # shape: (H, W), values in [0,3] ‚Äî corresponds to class index\n",
    "\n",
    "# === 7. Display or print the predicted mask values ===\n",
    "print(f\"Predicted mask shape: {final_mask.shape}\")\n",
    "print(f\"Unique predicted classes: {torch.unique(final_mask)}\")\n",
    "\n",
    "\n",
    "# Convert image tensor back to numpy for display (un-normalized)\n",
    "image_np = image_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Predicted mask: shape (H, W), values in [0, 3]\n",
    "mask_np = final_mask.cpu().numpy()\n",
    "\n",
    "# Optional: create a colormap for the 4 classes\n",
    "# Let's define: 0=cat, 1=dog, 2=background, 3=boundary\n",
    "cmap = np.array([\n",
    "    [255, 0, 0],     # red for cat\n",
    "    [0, 255, 0],     # green for dog\n",
    "    [0, 0, 0],       # black for background\n",
    "    [0, 0, 255],     # blue for boundary\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Map each class to color\n",
    "mask_rgb = cmap[mask_np]  # shape: (H, W, 3)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_np)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_rgb)\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First compute accuracy (IoU/Dice) on val_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC_DYSv0lEhj"
   },
   "source": [
    "treat boundary as a new class: boundary for now. currently we have 4 classes: [cat, dog, boundary, background],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(pred, target, num_classes):\n",
    "    \"\"\"Compute per-class IoU\"\"\"\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    return ious\n",
    "\n",
    "def compute_dice(pred, target, num_classes):\n",
    "    \"\"\"Compute per-class Dice coefficient\"\"\"\n",
    "    dices = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        total = pred_inds.sum().item() + target_inds.sum().item()\n",
    "        if total == 0:\n",
    "            dices.append(float('nan'))\n",
    "        else:\n",
    "            dices.append(2 * intersection / total)\n",
    "    return dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torchmetrics --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex  # IoU\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from unet import UNet\n",
    "from custom_dataset import CustomDataset\n",
    "\n",
    "# === Configuration ===\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = [\"Cat\", \"Dog\", \"Background\", \"Boundary\"]\n",
    "\n",
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\"\n",
    "MODEL_PATH = \"/Users/bin/Desktop/CV_Assignment/Model/unet_80_epochs.pth\"\n",
    "original_sizes_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load model ===\n",
    "model = UNet(in_channels=3, out_channels=NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === Load original sizes ===\n",
    "with open(original_sizes_path) as f:\n",
    "    original_sizes = json.load(f)\n",
    "\n",
    "# === Load validation dataset ===\n",
    "val_dataset = CustomDataset(\n",
    "    image_dir=os.path.join(base_dir, \"val_resized\", \"color\"),\n",
    "    mask_dir=os.path.join(base_dir, \"val_resized\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# === Define IoU metric ===\n",
    "iou_metric = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\").to(device)\n",
    "\n",
    "# === Evaluation loop ===\n",
    "with torch.no_grad():\n",
    "    for image, mask, img_name, _ in tqdm(val_loader):\n",
    "        image = image.to(device)\n",
    "        mask = mask.squeeze(0).to(device).long()\n",
    "\n",
    "        # Predict logits\n",
    "        logits = model(image)  # (1, 4, 256, 256)\n",
    "        pred_class = torch.argmax(logits, dim=1).float()  # (1, 256, 256)\n",
    "\n",
    "        # Resize prediction and GT back to original size\n",
    "        orig_h, orig_w = original_sizes[img_name[0]]\n",
    "        pred_resized = F.interpolate(pred_class.unsqueeze(1), size=(orig_h, orig_w), mode=\"nearest\").squeeze(1).long()\n",
    "        gt_resized = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=(orig_h, orig_w), mode=\"nearest\").squeeze(0).long()\n",
    "\n",
    "        # Update IoU metric (handles variable size)\n",
    "        iou_metric.update(pred_resized.to(device), gt_resized.to(device))\n",
    "\n",
    "# === Compute results ===\n",
    "iou_per_class = iou_metric.compute()  # shape: (num_classes,)\n",
    "\n",
    "print(\"\\nüìä Per-Class IoU:\")\n",
    "for i, iou in enumerate(iou_per_class):\n",
    "    print(f\"Class {i} ({CLASS_NAMES[i]}): IoU = {iou:.4f}\")\n",
    "\n",
    "mean_iou = iou_per_class[:3].mean()  # exclude boundary if needed\n",
    "print(f\"\\n‚û°Ô∏è Mean IoU (first 3 classes): {mean_iou:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
