{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1742674233437,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "AKxNh8g9eXZD"
   },
   "outputs": [],
   "source": [
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29367,
     "status": "ok",
     "timestamp": 1742674262762,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "d5pNrLzodT_7",
    "outputId": "b7a87a82-a418-452c-d202-651df541def9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AijK3ImLcWJ8"
   },
   "source": [
    "# split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742674262783,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "n1ZSBTrFcWJ9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Set seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "def trainval_split(base_dir):\n",
    "\n",
    "    # Define base directories\n",
    "    trainval_dir = os.path.join(base_dir, \"TrainVal\")\n",
    "    color_dir = os.path.join(trainval_dir, \"color\")\n",
    "    label_dir = os.path.join(trainval_dir, \"label\")\n",
    "\n",
    "    # Define destination directories for train and validation splits\n",
    "    train_color_dir = os.path.join(base_dir, \"train\", \"color\")\n",
    "    train_label_dir = os.path.join(base_dir, \"train\", \"label\")\n",
    "    val_color_dir = os.path.join(base_dir, \"val\", \"color\")\n",
    "    val_label_dir = os.path.join(base_dir, \"val\", \"label\")\n",
    "\n",
    "    # Create the destination directories if they don't exist\n",
    "    for d in [train_color_dir, train_label_dir, val_color_dir, val_label_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    # Find all jpg files in the color folder\n",
    "    image_files = glob.glob(os.path.join(color_dir, \"*.jpg\"))\n",
    "\n",
    "    # Group files by animal name (assumes format like \"Abyssinian_1.jpg\")\n",
    "    groups = {}\n",
    "    pattern = re.compile(r'(.+)_\\d+\\.jpg')  # capture group for the animal name\n",
    "    for image_file in image_files:\n",
    "        basename = os.path.basename(image_file)\n",
    "        match = pattern.match(basename)\n",
    "        if match:\n",
    "            animal = match.group(1)\n",
    "        else:\n",
    "            animal = \"unknown\"\n",
    "        groups.setdefault(animal, []).append(basename)\n",
    "\n",
    "    # Split the files for each animal into train (80%) and val (20%)\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    for animal, files in groups.items():\n",
    "        random.shuffle(files)\n",
    "        split_index = int(0.8 * len(files))\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "        train_list.extend(train_files)\n",
    "        val_list.extend(val_files)\n",
    "\n",
    "    # Define output text file paths\n",
    "    train_txt_path = os.path.join(base_dir, \"train.txt\")\n",
    "    val_txt_path = os.path.join(base_dir, \"val.txt\")\n",
    "\n",
    "    # Copy files to new folders and write paths to train.txt and val.txt\n",
    "    with open(train_txt_path, \"w\") as train_file, open(val_txt_path, \"w\") as val_file:\n",
    "        # Process train split\n",
    "        for filename in train_list:\n",
    "            # Copy color image\n",
    "            src_color = os.path.join(color_dir, filename)\n",
    "            dst_color = os.path.join(train_color_dir, filename)\n",
    "            shutil.copy2(src_color, dst_color)\n",
    "\n",
    "            # Derive corresponding label filename (change extension from .jpg to .png)\n",
    "            label_filename = filename.replace(\".jpg\", \".png\")\n",
    "            src_label = os.path.join(label_dir, label_filename)\n",
    "            dst_label = os.path.join(train_label_dir, label_filename)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "            # Write relative paths to train.txt (format: \"train/color/<filename> train/label/<label_filename>\")\n",
    "            train_file.write(f\"{os.path.join('train','color',filename)} {os.path.join('train','label',label_filename)}\\n\")\n",
    "\n",
    "        # Process validation split\n",
    "        for filename in val_list:\n",
    "            # Copy color image\n",
    "            src_color = os.path.join(color_dir, filename)\n",
    "            dst_color = os.path.join(val_color_dir, filename)\n",
    "            shutil.copy2(src_color, dst_color)\n",
    "\n",
    "            # Corresponding label filename\n",
    "            label_filename = filename.replace(\".jpg\", \".png\")\n",
    "            src_label = os.path.join(label_dir, label_filename)\n",
    "            dst_label = os.path.join(val_label_dir, label_filename)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "            # Write relative paths to val.txt\n",
    "            val_file.write(f\"{os.path.join('val','color',filename)} {os.path.join('val','label',label_filename)}\\n\")\n",
    "\n",
    "    print(\"Data splitting and copying complete.\")\n",
    "    print(f\"Train list written to {train_txt_path}\")\n",
    "    print(f\"Val list written to {val_txt_path}\")\n",
    "\n",
    "# trainval_split(base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6rP4qmcWJ_"
   },
   "source": [
    "# Resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMmA-9MqcWKA"
   },
   "source": [
    "initialize一个dictionary，对每个image resize之前，记录它对应的mask的height和width并写入字典，最后将字典写入一个叫original_sizes.json的file里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1742674262860,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "oVrKiDtMcWKA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Set target dimensions (adjust as needed)\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "target_size = (TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "# Directories for train and val splits\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "\n",
    "# Create destination directories:\n",
    "# For training, we resize images but copy masks unchanged.\n",
    "resized_train_color_dir = os.path.join(base_dir, \"train_resized\", \"color\")\n",
    "resized_train_label_dir = os.path.join(base_dir, \"train_resized\", \"label\")\n",
    "\n",
    "# For validation, we resize images and copy masks unchanged.\n",
    "resized_val_color_dir = os.path.join(base_dir, \"val_resized\", \"color\")\n",
    "resized_val_label_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "\n",
    "for d in [resized_train_color_dir, resized_train_label_dir,\n",
    "          resized_val_color_dir, resized_val_label_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Dictionary to store original image sizes before resizing\n",
    "original_sizes = {}\n",
    "\n",
    "def resize_and_save(src_path, dst_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize an image and save it (don't record size here anymore).\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error reading:\", src_path)\n",
    "        return\n",
    "    resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(dst_path, resized)\n",
    "\n",
    "def process_data(color_source, label_source, resized_color_dest, resized_label_dest, original_sizes_dict):\n",
    "    \"\"\"\n",
    "    Processes a dataset split:\n",
    "    - Resizes color images and saves them.\n",
    "    - Copies label masks unchanged, and stores their original sizes with clean keys.\n",
    "    \"\"\"\n",
    "    # Resize color images\n",
    "    for filename in sorted(os.listdir(color_source)):\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            src_path = os.path.join(color_source, filename)\n",
    "            dst_path = os.path.join(resized_color_dest, filename)\n",
    "            resize_and_save(src_path, dst_path, target_size)\n",
    "\n",
    "    # Copy masks and record original sizes\n",
    "    for filename in sorted(os.listdir(label_source)):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            src_path = os.path.join(label_source, filename)\n",
    "            dst_path = os.path.join(resized_label_dest, filename)\n",
    "\n",
    "            # Load mask\n",
    "            mask = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(\"Error reading mask:\", src_path)\n",
    "                continue\n",
    "\n",
    "            # 🔥 Clean filename key: remove suffix like \".png\"\n",
    "            img_key = os.path.splitext(filename)[0]  # \"Abyssinian_1.png\" → \"Abyssinian_1\"\n",
    "            original_sizes_dict[img_key] = list(mask.shape)  # Ensure JSON serializable: [H, W]\n",
    "\n",
    "            # Copy mask as-is\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Process Training Data\n",
    "# -----------------------------------------\n",
    "train_color_source = os.path.join(train_dir, \"color\")\n",
    "train_label_source = os.path.join(train_dir, \"label\")\n",
    "\n",
    "process_data(train_color_source, train_label_source, resized_train_color_dir, resized_train_label_dir, original_sizes)\n",
    "\n",
    "# # -----------------------------------------\n",
    "# # Process Validation Data\n",
    "# # -----------------------------------------\n",
    "val_color_source = os.path.join(val_dir, \"color\")\n",
    "val_label_source = os.path.join(val_dir, \"label\")\n",
    "\n",
    "process_data(val_color_source, val_label_source, resized_val_color_dir, resized_val_label_dir, original_sizes)\n",
    "\n",
    "# Save original sizes to a JSON file\n",
    "original_size_json_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "with open(original_size_json_path, \"w\") as f:\n",
    "    json.dump(original_sizes, f, indent=4)\n",
    "\n",
    "# print(f\"✅ Processing complete. Original sizes saved to {original_size_json_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN2nCJwScWKB"
   },
   "source": [
    "# randaugment (Do the augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1742674262861,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "-6bFQ4ohcWKB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import math\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# Define the RandAugment operation pool (14 ops as in the original paper)\n",
    "RA_OPERATIONS = [\n",
    "    \"Identity\", \"AutoContrast\", \"Equalize\",\n",
    "    \"Rotate\", \"Solarize\", \"Color\", \"Posterize\",\n",
    "    \"Contrast\", \"Brightness\", \"Sharpness\",\n",
    "    \"ShearX\", \"ShearY\", \"TranslateX\", \"TranslateY\"\n",
    "]\n",
    "\n",
    "def apply_operation(img, mask, op_name, magnitude):\n",
    "    \"\"\"\n",
    "    Apply a single augmentation operation to the image (and mask, if applicable).\n",
    "    'magnitude' is on a 0-10 scale indicating severity.\n",
    "    \"\"\"\n",
    "    if op_name == \"Identity\":\n",
    "        return img, mask  # no change\n",
    "\n",
    "    if op_name == \"AutoContrast\":\n",
    "        img = ImageOps.autocontrast(img)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Equalize\":\n",
    "        img = ImageOps.equalize(img)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Rotate\":\n",
    "        max_deg = 30.0\n",
    "        angle = magnitude / 10.0 * max_deg\n",
    "        if random.random() < 0.5:\n",
    "            angle = -angle\n",
    "        img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "        mask = mask.rotate(angle, resample=Image.NEAREST, fillcolor=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Solarize\":\n",
    "        thresh = int(256 - (magnitude / 10.0) * 256)\n",
    "        img = ImageOps.solarize(img, thresh)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Color\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Color(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Posterize\":\n",
    "        bits = int(round(8 - (magnitude / 10.0) * 4))\n",
    "        bits = max(1, bits)\n",
    "        img = ImageOps.posterize(img, bits)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Contrast\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Contrast(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Brightness\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Brightness(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Sharpness\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Sharpness(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    # Geometric operations: these need to be applied identically to the mask\n",
    "    if op_name == \"ShearX\":\n",
    "        shear_factor = magnitude / 10.0 * 0.3\n",
    "        if random.random() < 0.5:\n",
    "            shear_factor = -shear_factor\n",
    "        shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "        img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                       shear=(shear_degrees, 0.0),\n",
    "                       interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                        shear=(shear_degrees, 0.0),\n",
    "                        interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"ShearY\":\n",
    "        shear_factor = magnitude / 10.0 * 0.3\n",
    "        if random.random() < 0.5:\n",
    "            shear_factor = -shear_factor\n",
    "        shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "        img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                       shear=(0.0, shear_degrees),\n",
    "                       interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                        shear=(0.0, shear_degrees),\n",
    "                        interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"TranslateX\":\n",
    "        max_frac = 0.45\n",
    "        dx = int(round(magnitude / 10.0 * max_frac * img.width))\n",
    "        if random.random() < 0.5:\n",
    "            dx = -dx\n",
    "        img = F.affine(img, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "                       shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "                        shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"TranslateY\":\n",
    "        max_frac = 0.45\n",
    "        dy = int(round(magnitude / 10.0 * max_frac * img.height))\n",
    "        if random.random() < 0.5:\n",
    "            dy = -dy\n",
    "        img = F.affine(img, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "                       shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "                        shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "def randaugment_image_mask(img, mask, N, M):\n",
    "    \"\"\"Apply RandAugment (N operations with magnitude M) to the given PIL image and mask.\"\"\"\n",
    "    ops = random.sample(RA_OPERATIONS, N)  # choose N distinct ops at random\n",
    "    for op in ops:\n",
    "        img, mask = apply_operation(img, mask, op, M)\n",
    "    return img, mask\n",
    "\n",
    "def run_randaugment_train_resized(input_base, output_base, N=2, M=9, num_aug=3):\n",
    "    \"\"\"\n",
    "    Process each image-mask pair from the resized training data.\n",
    "\n",
    "    Expects:\n",
    "      - Images in:  input_base/train_resized/color\n",
    "      - Masks in:   input_base/train_resized/label\n",
    "\n",
    "    Saves augmented outputs in:\n",
    "      - output_base/train_randaugmented/color\n",
    "      - output_base/train_randaugmented/label\n",
    "\n",
    "    Additionally, copies the original image and mask.\n",
    "    Generates 'num_aug' augmented images per original image.\n",
    "    \"\"\"\n",
    "    in_img_dir = os.path.join(input_base, \"train_resized\", \"color\")\n",
    "    in_mask_dir = os.path.join(input_base, \"train_resized\", \"label\")\n",
    "    out_img_dir = os.path.join(output_base, \"train_randaugmented\", \"color\")\n",
    "    out_mask_dir = os.path.join(output_base, \"train_randaugmented\", \"label\")\n",
    "    os.makedirs(out_img_dir, exist_ok=True)\n",
    "    os.makedirs(out_mask_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(in_img_dir):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "        img_path = os.path.join(in_img_dir, filename)\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        # Try common mask extensions (often masks are stored as .png)\n",
    "        mask_candidates = [base_name + \".png\", base_name + \".jpg\", base_name + \".jpeg\", base_name + \".bmp\", base_name + \".tif\"]\n",
    "        mask_path = None\n",
    "        for cand in mask_candidates:\n",
    "            cand_path = os.path.join(in_mask_dir, cand)\n",
    "            if os.path.exists(cand_path):\n",
    "                mask_path = cand_path\n",
    "                break\n",
    "        if mask_path is None:\n",
    "            print(f\"Mask for image {filename} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "        if mask.mode not in [\"L\", \"I\"]:\n",
    "            mask = mask.convert(\"L\")\n",
    "\n",
    "        # Save the original image and mask in the output folders\n",
    "        orig_img_path = os.path.join(out_img_dir, f\"{base_name}_orig.jpg\")\n",
    "        orig_mask_path = os.path.join(out_mask_dir, f\"{base_name}_orig.png\")\n",
    "        img.save(orig_img_path)\n",
    "        mask.save(orig_mask_path)\n",
    "        print(f\"Saved original image to {orig_img_path} and mask to {orig_mask_path}\")\n",
    "\n",
    "        # Generate and save augmented versions\n",
    "        for i in range(num_aug):\n",
    "            aug_img, aug_mask = randaugment_image_mask(img, mask, N, M)\n",
    "            out_img_path = os.path.join(out_img_dir, f\"{base_name}_aug_{i}.jpg\")\n",
    "            out_mask_path = os.path.join(out_mask_dir, f\"{base_name}_aug_{i}.png\")\n",
    "            aug_img.save(out_img_path)\n",
    "            aug_mask.save(out_mask_path)\n",
    "            print(f\"Saved augmented image to {out_img_path} and mask to {out_mask_path}\")\n",
    "\n",
    "# --- Example usage in a notebook cell ---\n",
    "# Set your base directory. In your case, it is:\n",
    "# We'll use the same base directory for output (augmented data will be saved under a new subfolder)\n",
    "# run_randaugment_train_resized(base_dir, base_dir, N=2, M=9, num_aug=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EKuuM-NcWKB"
   },
   "source": [
    "将images和masks都写入DataLoader里，但同时也要记录每张image的name以便后面查询mask的original size\n",
    "除此以外，对于mask tensor化的操作还要更改。我们目前有4个class:[cat, dog, background, boundary] 分别对应class 0,1,2,3,我们通过默认的transforms.ToTensor()使得mask的每个tensor的每个像素都变为该像素的值后，我们还要进一步操作:对于每个tensor值，如果是0，就把该值变为2（意为background),如果是1，就把这个值变为3（意为boundary),如果是介于0-1之间的值，我们看这个mask的filename，如果filename的第一个字母是大写，将该值变为0(意为猫),反之如果是小写，就变成1（意为狗)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38043,
     "status": "ok",
     "timestamp": 1742674300889,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "4fDV4BMmcWKB"
   },
   "outputs": [],
   "source": [
    "from drive.MyDrive.CV_Assignment.custom_dataset import CustomDataset\n",
    "\n",
    "# Create dataset\n",
    "dataset = CustomDataset(\n",
    "    image_dir = os.path.join(base_dir, \"train_randaugmented\", \"color\"),\n",
    "    mask_dir = os.path.join(base_dir, \"train_randaugmented\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Custom collate function to handle filenames\n",
    "def custom_collate_fn(batch):\n",
    "    images, masks, img_names, mask_names = zip(*batch)\n",
    "\n",
    "    img_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in img_names]\n",
    "    mask_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in mask_names]\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    # masks = torch.stack(masks)\n",
    "    return images, list(masks), list(img_names), list(mask_names)\n",
    "\n",
    "# Create DataLoader with shuffle=True but keeping filenames\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Test DataLoader\n",
    "# for images, masks, img_names, mask_names in train_dataloader:\n",
    "#     print(\"Batch Image Filenames:\", img_names)\n",
    "#     print(\"Batch Mask Filenames:\", mask_names)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31562,
     "status": "ok",
     "timestamp": 1742674332449,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "tvPYU-cKcWKC",
    "outputId": "3db85f9f-9c9d-469d-882e-575bab7c9ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "from drive.MyDrive.CV_Assignment.unet import UNet\n",
    "import torch.optim as optim\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# summary(model=model,\n",
    "#         input_size=(32, 3, 256, 256), # make sure this is \"input_size\", not \"input_shape\"\n",
    "#         # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# )\n",
    "\n",
    "x = torch.randn(32, 3, 256, 256)  # Example input tensor\n",
    "output = model(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCZi4DnccWKC",
    "outputId": "0d3860fb-d4d8-4a92-b455-275f230f08c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "def resize_multiclass_logits(logits, img_names, original_sizes_dict):\n",
    "    resized_logits = []\n",
    "    for i in range(len(logits)):\n",
    "        name = img_names[i]\n",
    "        orig_h, orig_w = original_sizes_dict[name]\n",
    "        resized = F.interpolate(\n",
    "            logits[i].unsqueeze(0),  # shape (1, 4, 256, 256)\n",
    "            size=(orig_h, orig_w),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        resized_logits.append(resized.squeeze(0))  # shape: (4, H, W)\n",
    "    return resized_logits  # list of tensors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(base_dir, \"original_sizes.json\"), \"r\") as f:\n",
    "    original_sizes_dict = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define number of epochs\n",
    "NUM_EPOCHS = 10\n",
    "PRINT_INTERVAL = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop over multiple epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for images, masks, img_names, mask_names in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = [m.to(device) for m in masks]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1️⃣ Forward pass — output shape: (B, 4, 256, 256)\n",
    "        logits = model(images)\n",
    "\n",
    "        # 2️⃣ Resize each predicted logits map to original mask size\n",
    "        resized_logits = resize_multiclass_logits(logits, img_names, original_sizes_dict)  # List of (4, H, W)\n",
    "\n",
    "        # 3️⃣ Compute per-sample loss (cross entropy expects (C, H, W) + (H, W))\n",
    "        total_loss = 0\n",
    "        for pred_logits, gt_mask in zip(resized_logits, masks):\n",
    "          # Add batch dimension to both tensors\n",
    "          pred_logits = pred_logits.unsqueeze(0)  # shape: (1, 4, H, W)\n",
    "          gt_mask = gt_mask.unsqueeze(0)          # shape: (1, H, W)\n",
    "\n",
    "          loss = loss_fn(pred_logits, gt_mask)\n",
    "          total_loss += loss\n",
    "\n",
    "        # 5️⃣ Backward + update\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % PRINT_INTERVAL == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"🎉 Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC_DYSv0lEhj"
   },
   "source": [
    "treat boundary as a new class: boundary for now. currently we have 4 classes: [cat, dog, boundary, background],"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
