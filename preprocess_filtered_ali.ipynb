{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1742674233437,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "AKxNh8g9eXZD"
   },
   "outputs": [],
   "source": [
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29367,
     "status": "ok",
     "timestamp": 1742674262762,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "d5pNrLzodT_7",
    "outputId": "b7a87a82-a418-452c-d202-651df541def9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "try:\n",
    "    import torchinfo\n",
    "except:\n",
    "    !pip install torchinfo\n",
    "    import torchinfo\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AijK3ImLcWJ8"
   },
   "source": [
    "# split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1742674262783,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "n1ZSBTrFcWJ9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Set seed for reproducibility\n",
    "# random.seed(42)\n",
    "\n",
    "def trainval_split(base_dir):\n",
    "\n",
    "    # Define base directories\n",
    "    trainval_dir = os.path.join(base_dir, \"TrainVal\")\n",
    "    color_dir = os.path.join(trainval_dir, \"color\")\n",
    "    label_dir = os.path.join(trainval_dir, \"label\")\n",
    "\n",
    "    # Define destination directories for train and validation splits\n",
    "    train_color_dir = os.path.join(base_dir, \"train\", \"color\")\n",
    "    train_label_dir = os.path.join(base_dir, \"train\", \"label\")\n",
    "    val_color_dir = os.path.join(base_dir, \"val\", \"color\")\n",
    "    val_label_dir = os.path.join(base_dir, \"val\", \"label\")\n",
    "\n",
    "    # Create the destination directories if they don't exist\n",
    "    for d in [train_color_dir, train_label_dir, val_color_dir, val_label_dir]:\n",
    "        os.makedirs(d, exist_ok=True)\n",
    "\n",
    "    # Find all jpg files in the color folder\n",
    "    image_files = glob.glob(os.path.join(color_dir, \"*.jpg\"))\n",
    "\n",
    "    # Group files by animal name (assumes format like \"Abyssinian_1.jpg\")\n",
    "    groups = {}\n",
    "    pattern = re.compile(r'(.+)_\\d+\\.jpg')  # capture group for the animal name\n",
    "    for image_file in image_files:\n",
    "        basename = os.path.basename(image_file)\n",
    "        match = pattern.match(basename)\n",
    "        if match:\n",
    "            animal = match.group(1)\n",
    "        else:\n",
    "            animal = \"unknown\"\n",
    "        groups.setdefault(animal, []).append(basename)\n",
    "\n",
    "    # Split the files for each animal into train (80%) and val (20%)\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    for animal, files in groups.items():\n",
    "        random.shuffle(files)\n",
    "        split_index = int(0.8 * len(files))\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "        train_list.extend(train_files)\n",
    "        val_list.extend(val_files)\n",
    "\n",
    "    # Define output text file paths\n",
    "    train_txt_path = os.path.join(base_dir, \"train.txt\")\n",
    "    val_txt_path = os.path.join(base_dir, \"val.txt\")\n",
    "\n",
    "    # Copy files to new folders and write paths to train.txt and val.txt\n",
    "    with open(train_txt_path, \"w\") as train_file, open(val_txt_path, \"w\") as val_file:\n",
    "        # Process train split\n",
    "        for filename in train_list:\n",
    "            # Copy color image\n",
    "            src_color = os.path.join(color_dir, filename)\n",
    "            dst_color = os.path.join(train_color_dir, filename)\n",
    "            shutil.copy2(src_color, dst_color)\n",
    "\n",
    "            # Derive corresponding label filename (change extension from .jpg to .png)\n",
    "            label_filename = filename.replace(\".jpg\", \".png\")\n",
    "            src_label = os.path.join(label_dir, label_filename)\n",
    "            dst_label = os.path.join(train_label_dir, label_filename)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "            # Write relative paths to train.txt (format: \"train/color/<filename> train/label/<label_filename>\")\n",
    "            train_file.write(f\"{os.path.join('train','color',filename)} {os.path.join('train','label',label_filename)}\\n\")\n",
    "\n",
    "        # Process validation split\n",
    "        for filename in val_list:\n",
    "            # Copy color image\n",
    "            src_color = os.path.join(color_dir, filename)\n",
    "            dst_color = os.path.join(val_color_dir, filename)\n",
    "            shutil.copy2(src_color, dst_color)\n",
    "\n",
    "            # Corresponding label filename\n",
    "            label_filename = filename.replace(\".jpg\", \".png\")\n",
    "            src_label = os.path.join(label_dir, label_filename)\n",
    "            dst_label = os.path.join(val_label_dir, label_filename)\n",
    "            if os.path.exists(src_label):\n",
    "                shutil.copy2(src_label, dst_label)\n",
    "\n",
    "            # Write relative paths to val.txt\n",
    "            val_file.write(f\"{os.path.join('val','color',filename)} {os.path.join('val','label',label_filename)}\\n\")\n",
    "\n",
    "    print(\"Data splitting and copying complete.\")\n",
    "    print(f\"Train list written to {train_txt_path}\")\n",
    "    print(f\"Val list written to {val_txt_path}\")\n",
    "\n",
    "# trainval_split(base_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dy6rP4qmcWJ_"
   },
   "source": [
    "# Resize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMmA-9MqcWKA"
   },
   "source": [
    "initialize一个dictionary，对每个image resize之前，记录它对应的mask的height和width并写入字典，最后将字典写入一个叫original_sizes.json的file里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1742674262860,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "oVrKiDtMcWKA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Set target dimensions (adjust as needed)\n",
    "TARGET_WIDTH = 256\n",
    "TARGET_HEIGHT = 256\n",
    "target_size = (TARGET_WIDTH, TARGET_HEIGHT)\n",
    "\n",
    "# Directories for train and val splits\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir = os.path.join(base_dir, \"val\")\n",
    "\n",
    "# Create destination directories:\n",
    "# For training, we resize images but copy masks unchanged.\n",
    "resized_train_color_dir = os.path.join(base_dir, \"train_resized\", \"color\")\n",
    "resized_train_label_dir = os.path.join(base_dir, \"train_resized\", \"label\")\n",
    "\n",
    "# For validation, we resize images and copy masks unchanged.\n",
    "resized_val_color_dir = os.path.join(base_dir, \"val_resized\", \"color\")\n",
    "resized_val_label_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "\n",
    "for d in [resized_train_color_dir, resized_train_label_dir,\n",
    "          resized_val_color_dir, resized_val_label_dir]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "# Dictionary to store original image sizes before resizing\n",
    "original_sizes = {}\n",
    "\n",
    "def resize_and_save(src_path, dst_path, target_size):\n",
    "    \"\"\"\n",
    "    Resize an image and save it (don't record size here anymore).\n",
    "    \"\"\"\n",
    "    img = cv2.imread(src_path, cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Error reading:\", src_path)\n",
    "        return\n",
    "    resized = cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite(dst_path, resized)\n",
    "\n",
    "def process_data(color_source, label_source, resized_color_dest, resized_label_dest, original_sizes_dict):\n",
    "    \"\"\"\n",
    "    Processes a dataset split:\n",
    "    - Resizes color images and saves them.\n",
    "    - Copies label masks unchanged, and stores their original sizes with clean keys.\n",
    "    \"\"\"\n",
    "    # Resize color images\n",
    "    for filename in sorted(os.listdir(color_source)):\n",
    "        if filename.lower().endswith(\".jpg\"):\n",
    "            src_path = os.path.join(color_source, filename)\n",
    "            dst_path = os.path.join(resized_color_dest, filename)\n",
    "            resize_and_save(src_path, dst_path, target_size)\n",
    "\n",
    "    # Copy masks and record original sizes\n",
    "    for filename in sorted(os.listdir(label_source)):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            src_path = os.path.join(label_source, filename)\n",
    "            dst_path = os.path.join(resized_label_dest, filename)\n",
    "\n",
    "            # Load mask\n",
    "            mask = cv2.imread(src_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                print(\"Error reading mask:\", src_path)\n",
    "                continue\n",
    "\n",
    "            # 🔥 Clean filename key: remove suffix like \".png\"\n",
    "            img_key = os.path.splitext(filename)[0]  # \"Abyssinian_1.png\" → \"Abyssinian_1\"\n",
    "            original_sizes_dict[img_key] = list(mask.shape)  # Ensure JSON serializable: [H, W]\n",
    "\n",
    "            # Copy mask as-is\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# -----------------------------------------\n",
    "# Process Training Data\n",
    "# -----------------------------------------\n",
    "train_color_source = os.path.join(train_dir, \"color\")\n",
    "train_label_source = os.path.join(train_dir, \"label\")\n",
    "\n",
    "# process_data(train_color_source, train_label_source, resized_train_color_dir, resized_train_label_dir, original_sizes)\n",
    "\n",
    "# # -----------------------------------------\n",
    "# # Process Validation Data\n",
    "# # -----------------------------------------\n",
    "val_color_source = os.path.join(val_dir, \"color\")\n",
    "val_label_source = os.path.join(val_dir, \"label\")\n",
    "\n",
    "# process_data(val_color_source, val_label_source, resized_val_color_dir, resized_val_label_dir, original_sizes)\n",
    "\n",
    "# Save original sizes to a JSON file\n",
    "original_size_json_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "with open(original_size_json_path, \"w\") as f:\n",
    "    json.dump(original_sizes, f, indent=4)\n",
    "\n",
    "# print(f\"✅ Processing complete. Original sizes saved to {original_size_json_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN2nCJwScWKB"
   },
   "source": [
    "# randaugment (Do the augmentations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1742674262861,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "-6bFQ4ohcWKB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "import math\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "# Define the RandAugment operation pool (14 ops as in the original paper)\n",
    "RA_OPERATIONS = [\n",
    "    \"Identity\", \"AutoContrast\", \"Equalize\",\n",
    "    \"Rotate\", \"Solarize\", \"Color\", \"Posterize\",\n",
    "    \"Contrast\", \"Brightness\", \"Sharpness\",\n",
    "    \"ShearX\", \"ShearY\", \"TranslateX\", \"TranslateY\"\n",
    "]\n",
    "\n",
    "def apply_operation(img, mask, op_name, magnitude):\n",
    "    \"\"\"\n",
    "    Apply a single augmentation operation to the image (and mask, if applicable).\n",
    "    'magnitude' is on a 0-10 scale indicating severity.\n",
    "    \"\"\"\n",
    "    if op_name == \"Identity\":\n",
    "        return img, mask  # no change\n",
    "\n",
    "    if op_name == \"AutoContrast\":\n",
    "        img = ImageOps.autocontrast(img)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Equalize\":\n",
    "        img = ImageOps.equalize(img)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Rotate\":\n",
    "        max_deg = 30.0\n",
    "        angle = magnitude / 10.0 * max_deg\n",
    "        if random.random() < 0.5:\n",
    "            angle = -angle\n",
    "        img = img.rotate(angle, resample=Image.BILINEAR, fillcolor=0)\n",
    "        mask = mask.rotate(angle, resample=Image.NEAREST, fillcolor=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Solarize\":\n",
    "        thresh = int(256 - (magnitude / 10.0) * 256)\n",
    "        img = ImageOps.solarize(img, thresh)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Color\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Color(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Posterize\":\n",
    "        bits = int(round(8 - (magnitude / 10.0) * 4))\n",
    "        bits = max(1, bits)\n",
    "        img = ImageOps.posterize(img, bits)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Contrast\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Contrast(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Brightness\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Brightness(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"Sharpness\":\n",
    "        factor = 1.0 + (magnitude / 10.0) * 0.9\n",
    "        if random.random() < 0.5:\n",
    "            factor = 1.0 - (magnitude / 10.0) * 0.9\n",
    "        img = ImageEnhance.Sharpness(img).enhance(factor)\n",
    "        return img, mask\n",
    "\n",
    "    # Geometric operations: these need to be applied identically to the mask\n",
    "    if op_name == \"ShearX\":\n",
    "        shear_factor = magnitude / 10.0 * 0.3\n",
    "        if random.random() < 0.5:\n",
    "            shear_factor = -shear_factor\n",
    "        shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "        img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                       shear=(shear_degrees, 0.0),\n",
    "                       interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                        shear=(shear_degrees, 0.0),\n",
    "                        interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"ShearY\":\n",
    "        shear_factor = magnitude / 10.0 * 0.3\n",
    "        if random.random() < 0.5:\n",
    "            shear_factor = -shear_factor\n",
    "        shear_degrees = math.degrees(math.atan(shear_factor))\n",
    "        img = F.affine(img, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                       shear=(0.0, shear_degrees),\n",
    "                       interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, 0), scale=1.0,\n",
    "                        shear=(0.0, shear_degrees),\n",
    "                        interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"TranslateX\":\n",
    "        max_frac = 0.45\n",
    "        dx = int(round(magnitude / 10.0 * max_frac * img.width))\n",
    "        if random.random() < 0.5:\n",
    "            dx = -dx\n",
    "        img = F.affine(img, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "                       shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(dx, 0), scale=1.0,\n",
    "                        shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    if op_name == \"TranslateY\":\n",
    "        max_frac = 0.45\n",
    "        dy = int(round(magnitude / 10.0 * max_frac * img.height))\n",
    "        if random.random() < 0.5:\n",
    "            dy = -dy\n",
    "        img = F.affine(img, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "                       shear=(0.0, 0.0), interpolation=InterpolationMode.BILINEAR, fill=0)\n",
    "        mask = F.affine(mask, angle=0.0, translate=(0, dy), scale=1.0,\n",
    "                        shear=(0.0, 0.0), interpolation=InterpolationMode.NEAREST, fill=0)\n",
    "        return img, mask\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "def randaugment_image_mask(img, mask, N, M):\n",
    "    \"\"\"Apply RandAugment (N operations with magnitude M) to the given PIL image and mask.\"\"\"\n",
    "    ops = random.sample(RA_OPERATIONS, N)  # choose N distinct ops at random\n",
    "    for op in ops:\n",
    "        img, mask = apply_operation(img, mask, op, M)\n",
    "    return img, mask\n",
    "\n",
    "def run_randaugment_train_resized(input_base, output_base, N=2, M=9, num_aug=3):\n",
    "    \"\"\"\n",
    "    Process each image-mask pair from the resized training data.\n",
    "\n",
    "    Expects:\n",
    "      - Images in:  input_base/train_resized/color\n",
    "      - Masks in:   input_base/train_resized/label\n",
    "\n",
    "    Saves augmented outputs in:\n",
    "      - output_base/train_randaugmented/color\n",
    "      - output_base/train_randaugmented/label\n",
    "\n",
    "    Additionally, copies the original image and mask.\n",
    "    Generates 'num_aug' augmented images per original image.\n",
    "    \"\"\"\n",
    "    in_img_dir = os.path.join(input_base, \"train_resized\", \"color\")\n",
    "    in_mask_dir = os.path.join(input_base, \"train_resized\", \"label\")\n",
    "    out_img_dir = os.path.join(output_base, \"train_randaugmented\", \"color\")\n",
    "    out_mask_dir = os.path.join(output_base, \"train_randaugmented\", \"label\")\n",
    "    os.makedirs(out_img_dir, exist_ok=True)\n",
    "    os.makedirs(out_mask_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(in_img_dir):\n",
    "        if not filename.lower().endswith(\".jpg\"):\n",
    "            continue\n",
    "        img_path = os.path.join(in_img_dir, filename)\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        # Try common mask extensions (often masks are stored as .png)\n",
    "        mask_candidates = [base_name + \".png\", base_name + \".jpg\", base_name + \".jpeg\", base_name + \".bmp\", base_name + \".tif\"]\n",
    "        mask_path = None\n",
    "        for cand in mask_candidates:\n",
    "            cand_path = os.path.join(in_mask_dir, cand)\n",
    "            if os.path.exists(cand_path):\n",
    "                mask_path = cand_path\n",
    "                break\n",
    "        if mask_path is None:\n",
    "            print(f\"Mask for image {filename} not found, skipping.\")\n",
    "            continue\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "        if mask.mode not in [\"L\", \"I\"]:\n",
    "            mask = mask.convert(\"L\")\n",
    "\n",
    "        # Save the original image and mask in the output folders\n",
    "        orig_img_path = os.path.join(out_img_dir, f\"{base_name}_orig.jpg\")\n",
    "        orig_mask_path = os.path.join(out_mask_dir, f\"{base_name}_orig.png\")\n",
    "        img.save(orig_img_path)\n",
    "        mask.save(orig_mask_path)\n",
    "        print(f\"Saved original image to {orig_img_path} and mask to {orig_mask_path}\")\n",
    "\n",
    "        # Generate and save augmented versions\n",
    "        for i in range(num_aug):\n",
    "            aug_img, aug_mask = randaugment_image_mask(img, mask, N, M)\n",
    "            out_img_path = os.path.join(out_img_dir, f\"{base_name}_aug_{i}.jpg\")\n",
    "            out_mask_path = os.path.join(out_mask_dir, f\"{base_name}_aug_{i}.png\")\n",
    "            aug_img.save(out_img_path)\n",
    "            aug_mask.save(out_mask_path)\n",
    "            print(f\"Saved augmented image to {out_img_path} and mask to {out_mask_path}\")\n",
    "\n",
    "# --- Example usage in a notebook cell ---\n",
    "# Set your base directory. In your case, it is:\n",
    "# We'll use the same base directory for output (augmented data will be saved under a new subfolder)\n",
    "# run_randaugment_train_resized(base_dir, base_dir, N=2, M=9, num_aug=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EKuuM-NcWKB"
   },
   "source": [
    "将images和masks都写入DataLoader里，但同时也要记录每张image的name以便后面查询mask的original size\n",
    "除此以外，对于mask tensor化的操作还要更改。我们目前有4个class:[cat, dog, background, boundary] 分别对应class 0,1,2,3,我们通过默认的transforms.ToTensor()使得mask的每个tensor的每个像素都变为该像素的值后，我们还要进一步操作:对于每个tensor值，如果是0，就把该值变为2（意为background),如果是1，就把这个值变为3（意为boundary),如果是介于0-1之间的值，我们看这个mask的filename，如果filename的第一个字母是大写，将该值变为0(意为猫),反之如果是小写，就变成1（意为狗)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 38043,
     "status": "ok",
     "timestamp": 1742674300889,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "4fDV4BMmcWKB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique class indices and pixel counts:\n",
      "Class 1: 17542 pixels\n",
      "Class 2: 36833 pixels\n",
      "Class 3: 5925 pixels\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from drive.MyDrive.CV_Assignment.custom_dataset import CustomDataset\n",
    "from custom_dataset import CustomDataset\n",
    "# Create dataset\n",
    "dataset = CustomDataset(\n",
    "    image_dir = os.path.join(base_dir, \"train_randaugmented\", \"color\"),\n",
    "    mask_dir = os.path.join(base_dir, \"train_randaugmented\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "\n",
    "# Custom collate function to handle filenames\n",
    "def custom_collate_fn(batch):\n",
    "    images, masks, img_names, mask_names = zip(*batch)\n",
    "\n",
    "    img_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in img_names]\n",
    "    mask_names = [re.sub(r'(_aug_\\d+|_orig)$', '', name) for name in mask_names]\n",
    "\n",
    "    images = torch.stack(images)\n",
    "    # masks = torch.stack(masks)\n",
    "    return images, list(masks), list(img_names), list(mask_names)\n",
    "\n",
    "# Create DataLoader with shuffle=True but keeping filenames\n",
    "train_dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Test DataLoader\n",
    "# for images, masks, img_names, mask_names in train_dataloader:\n",
    "#     print(\"Batch Image Filenames:\", img_names)\n",
    "#     print(\"Batch Mask Filenames:\", mask_names)\n",
    "#     break\n",
    "\n",
    "# 取第一个 batch\n",
    "# first_batch = next(iter(train_dataloader))\n",
    "\n",
    "# # 解包 batch 内容\n",
    "# images, masks, img_names, mask_names = first_batch\n",
    "\n",
    "# # 取第一个掩膜\n",
    "# first_mask = masks[0]  # LongTensor, shape: (H, W)\n",
    "\n",
    "# # 查看唯一类别标签及其像素数量\n",
    "# unique_classes, counts = torch.unique(first_mask, return_counts=True)\n",
    "# print(\"Unique class indices and pixel counts:\")\n",
    "# for cls, count in zip(unique_classes.tolist(), counts.tolist()):\n",
    "#     print(f\"Class {cls}: {count} pixels\")\n",
    "\n",
    "# # 可视化掩膜\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(first_mask, cmap=\"gray\")\n",
    "# plt.title(f\"Mask: {mask_names[0]}\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define path and list mask files\n",
    "mask_dir = os.path.join(base_dir, \"val_resized\", \"label\")\n",
    "mask_files = [f for f in os.listdir(mask_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Step 2: Pick a random file\n",
    "random_mask_file = random.choice(mask_files)\n",
    "mask_path = os.path.join(mask_dir, random_mask_file)\n",
    "\n",
    "# Step 3: Open the image (no conversion)\n",
    "mask = Image.open(mask_path)\n",
    "\n",
    "# Step 4: Convert to tensor\n",
    "mask_tensor = transforms.ToTensor()(mask)  # Shape: (C, H, W)\n",
    "\n",
    "print(f\"Loaded mask: {random_mask_file}\")\n",
    "print(f\"Tensor shape: {mask_tensor.shape}\")\n",
    "\n",
    "# Step 5: Find unique pixel values\n",
    "if mask_tensor.ndim == 3 and mask_tensor.shape[0] == 3:  # RGB\n",
    "    pixels = mask_tensor.view(3, -1).permute(1, 0)  # shape: (H*W, 3)\n",
    "    pixels = torch.round(pixels * 255).to(torch.uint8)\n",
    "    unique_colors, counts = torch.unique(pixels, return_counts=True, dim=0)\n",
    "\n",
    "    print(\"Unique RGB pixel values and their counts:\")\n",
    "    for color, count in zip(unique_colors, counts):\n",
    "        print(f\"{color.tolist()} --> {count.item()} pixels\")\n",
    "\n",
    "else:  # Grayscale or single-channel\n",
    "    mask_flat = mask_tensor.view(-1)\n",
    "    unique_values, counts = torch.unique(mask_flat, return_counts=True)\n",
    "\n",
    "    print(\"Unique grayscale pixel values and their counts:\")\n",
    "    for val, count in zip(unique_values, counts):\n",
    "        print(f\"{val.item():.6f} --> {count.item()} pixels\")\n",
    "\n",
    "# Step 6: Display the mask image\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(f\"Random Mask: {random_mask_file}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31562,
     "status": "ok",
     "timestamp": 1742674332449,
     "user": {
      "displayName": "Guoyue Jeong",
      "userId": "09880000638306830958"
     },
     "user_tz": 0
    },
    "id": "tvPYU-cKcWKC",
    "outputId": "3db85f9f-9c9d-469d-882e-575bab7c9ff4"
   },
   "outputs": [],
   "source": [
    "# from drive.MyDrive.CV_Assignment.unet import UNet\n",
    "# import torch.optim as optim\n",
    "\n",
    "# model = UNet(in_channels=3, out_channels=4)\n",
    "\n",
    "# # Move model to GPU if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "# x = torch.randn(32, 3, 256, 256)  # Example input tensor\n",
    "# output = model(x)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sCZi4DnccWKC",
    "outputId": "0d3860fb-d4d8-4a92-b455-275f230f08c6"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def resize_multiclass_logits(logits, img_names, original_sizes_dict):\n",
    "    resized_logits = []\n",
    "    for i in range(len(logits)):\n",
    "        name = img_names[i]\n",
    "        orig_h, orig_w = original_sizes_dict[name]\n",
    "        resized = F.interpolate(\n",
    "            logits[i].unsqueeze(0),  # shape (1, 4, 256, 256)\n",
    "            size=(orig_h, orig_w),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False\n",
    "        )\n",
    "        resized_logits.append(resized.squeeze(0))  # shape: (4, H, W)\n",
    "    return resized_logits  # list of tensors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(base_dir, \"original_sizes.json\"), \"r\") as f:\n",
    "    original_sizes_dict = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define number of epochs\n",
    "NUM_EPOCHS = 100\n",
    "PRINT_INTERVAL = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop over multiple epochs\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for images, masks, img_names, mask_names in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = [m.to(device) for m in masks]\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 1️⃣ Forward pass — output shape: (B, 4, 256, 256)\n",
    "        logits = model(images)\n",
    "\n",
    "        # 2️⃣ Resize each predicted logits map to original mask size\n",
    "        resized_logits = resize_multiclass_logits(logits, img_names, original_sizes_dict)  # List of (4, H, W)\n",
    "\n",
    "        # 3️⃣ Compute per-sample loss (cross entropy expects (C, H, W) + (H, W))\n",
    "        total_loss = 0\n",
    "        for pred_logits, gt_mask in zip(resized_logits, masks):\n",
    "          # Add batch dimension to both tensors\n",
    "          pred_logits = pred_logits.unsqueeze(0)  # shape: (1, 4, H, W)\n",
    "          gt_mask = gt_mask.unsqueeze(0)          # shape: (1, H, W)\n",
    "\n",
    "          loss = loss_fn(pred_logits, gt_mask)\n",
    "          total_loss += loss\n",
    "\n",
    "        # 5️⃣ Backward + update\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += total_loss.item()\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_dataloader)\n",
    "\n",
    "    if (epoch + 1) % PRINT_INTERVAL == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] - Loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"🎉 Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the predicted mask of a random image from val_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define your model architecture ---\n",
    "# Dummy example: Replace with your actual UNet model class\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === 2. Load model ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(in_channels=3, out_channels=4).to(device)\n",
    "model.load_state_dict(torch.load(\"/Users/bin/Desktop/CV_Assignment/Model/unet_100_epochs.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === 3. Load original size dictionary ===\n",
    "with open(\"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/original_sizes.json\", \"r\") as f:\n",
    "    original_sizes = json.load(f)\n",
    "\n",
    "# === 4. Load and transform image ===\n",
    "val_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered/val_resized/color\"\n",
    "img_names = sorted(os.listdir(val_dir))\n",
    "img_name = random.choice(img_names)\n",
    "img_path = os.path.join(val_dir, img_name)\n",
    "img_key = os.path.splitext(img_name)[0]\n",
    "\n",
    "print(f\"Predicting on image: {img_name}\")\n",
    "\n",
    "# Resize transform (same as training)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image = Image.open(img_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)  # shape: (1, 3, 256, 256)\n",
    "\n",
    "# === 5. Predict logits ===\n",
    "with torch.no_grad():\n",
    "    logits = model(image_tensor)  # shape: (1, 4, 256, 256)\n",
    "    pred_class = torch.argmax(logits, dim=1, keepdim=True)  # shape: (1, 1, 256, 256)\n",
    "\n",
    "    # === 6. Resize predicted mask back to original size ===\n",
    "    orig_h, orig_w = original_sizes[img_key]\n",
    "    pred_resized = torch.nn.functional.interpolate(pred_class.float(), size=(orig_h, orig_w), mode=\"nearest\")  # shape: (1, 1, H, W)\n",
    "    print(\"Unique predicted class values:\", torch.unique(pred_resized))\n",
    "    final_mask = pred_resized.squeeze().cpu().long()  # shape: (H, W), values in [0,3] — corresponds to class index\n",
    "\n",
    "# === 7. Display or print the predicted mask values ===\n",
    "print(f\"Predicted mask shape: {final_mask.shape}\")\n",
    "print(f\"Unique predicted classes: {torch.unique(final_mask)}\")\n",
    "\n",
    "\n",
    "# Convert image tensor back to numpy for display (un-normalized)\n",
    "image_np = image_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Predicted mask: shape (H, W), values in [0, 3]\n",
    "mask_np = final_mask.cpu().numpy()\n",
    "\n",
    "# Optional: create a colormap for the 4 classes\n",
    "# Let's define: 0=cat, 1=dog, 2=background, 3=boundary\n",
    "cmap = np.array([\n",
    "    [255, 0, 0],     # red for cat\n",
    "    [0, 255, 0],     # green for dog\n",
    "    [0, 0, 0],       # black for background\n",
    "    [0, 0, 255],     # blue for boundary\n",
    "], dtype=np.uint8)\n",
    "\n",
    "# Map each class to color\n",
    "mask_rgb = cmap[mask_np]  # shape: (H, W, 3)\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image_np)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask_rgb)\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#First compute accuracy (IoU/Dice) on val_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC_DYSv0lEhj"
   },
   "source": [
    "treat boundary as a new class: boundary for now. currently we have 4 classes: [cat, dog, boundary, background],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(pred, target, num_classes):\n",
    "    \"\"\"Compute per-class IoU\"\"\"\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    return ious\n",
    "\n",
    "def compute_dice(pred, target, num_classes):\n",
    "    \"\"\"Compute per-class Dice coefficient\"\"\"\n",
    "    dices = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        total = pred_inds.sum().item() + target_inds.sum().item()\n",
    "        if total == 0:\n",
    "            dices.append(float('nan'))\n",
    "        else:\n",
    "            dices.append(2 * intersection / total)\n",
    "    return dices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torchmetrics --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import JaccardIndex  # IoU\n",
    "import os, json\n",
    "from tqdm import tqdm\n",
    "from unet import UNet\n",
    "from custom_dataset import CustomDataset\n",
    "\n",
    "# === Configuration ===\n",
    "NUM_CLASSES = 4\n",
    "CLASS_NAMES = [\"Cat\", \"Dog\", \"Background\", \"Boundary\"]\n",
    "\n",
    "base_dir = \"/Users/bin/Desktop/CV_Assignment/Dataset_filtered\"\n",
    "MODEL_PATH = \"/Users/bin/Desktop/CV_Assignment/Model/unet_80_epochs.pth\"\n",
    "original_sizes_path = os.path.join(base_dir, \"original_sizes.json\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Load model ===\n",
    "model = UNet(in_channels=3, out_channels=NUM_CLASSES).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# === Load original sizes ===\n",
    "with open(original_sizes_path) as f:\n",
    "    original_sizes = json.load(f)\n",
    "\n",
    "# === Load validation dataset ===\n",
    "val_dataset = CustomDataset(\n",
    "    image_dir=os.path.join(base_dir, \"val_resized\", \"color\"),\n",
    "    mask_dir=os.path.join(base_dir, \"val_resized\", \"label\"),\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# === Define IoU metric ===\n",
    "iou_metric = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=\"none\").to(device)\n",
    "\n",
    "# === Evaluation loop ===\n",
    "with torch.no_grad():\n",
    "    for image, mask, img_name, _ in tqdm(val_loader):\n",
    "        image = image.to(device)\n",
    "        mask = mask.squeeze(0).to(device).long()\n",
    "\n",
    "        # Predict logits\n",
    "        logits = model(image)  # (1, 4, 256, 256)\n",
    "        pred_class = torch.argmax(logits, dim=1).float()  # (1, 256, 256)\n",
    "\n",
    "        # Resize prediction and GT back to original size\n",
    "        orig_h, orig_w = original_sizes[img_name[0]]\n",
    "        pred_resized = F.interpolate(pred_class.unsqueeze(1), size=(orig_h, orig_w), mode=\"nearest\").squeeze(1).long()\n",
    "        gt_resized = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=(orig_h, orig_w), mode=\"nearest\").squeeze(0).long()\n",
    "\n",
    "        # Update IoU metric (handles variable size)\n",
    "        iou_metric.update(pred_resized.to(device), gt_resized.to(device))\n",
    "\n",
    "# === Compute results ===\n",
    "iou_per_class = iou_metric.compute()  # shape: (num_classes,)\n",
    "\n",
    "print(\"\\n📊 Per-Class IoU:\")\n",
    "for i, iou in enumerate(iou_per_class):\n",
    "    print(f\"Class {i} ({CLASS_NAMES[i]}): IoU = {iou:.4f}\")\n",
    "\n",
    "mean_iou = iou_per_class[:3].mean()  # exclude boundary if needed\n",
    "print(f\"\\n➡️ Mean IoU (first 3 classes): {mean_iou:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
